{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Sign Detection with Faster RCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries\n",
    "\n",
    "Install pycocotools along with the other libraries imported.\n",
    "\n",
    "pip install pycocotools\n",
    "\n",
    "\n",
    "##### Files needed:\n",
    "\n",
    "COCO Evaluation metrics and some transform functions were used in this code. The [Torchvision Git repo](https://github.com/pytorch/vision/tree/master/references/detection) provides an API for COCO evaluation, transforms and other useful stuff used in object detection. These files are required to be placed in the root directory of the project.\n",
    "\n",
    "./coco_eval.py\n",
    "./coco_utils.py\n",
    "./engine.py\n",
    "./transforms.py\n",
    "./utils.py\n",
    "\n",
    "\n",
    "Note: I had some conflicts while importing these files. For example, utils.py. They probably won't work out of the box. I've also made a few simple changes to return evaluation metrics while training, you could download the files I used from my [Git repo](https://github.com/haxothermic/Traffic-Sign-Detection-with-Faster-R-CNN-using-PyTorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T07:42:16.133177457Z",
     "start_time": "2023-11-23T07:42:13.609759899Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Image data and annotations\n",
    "\n",
    "[Information about Dataset](http://benchmark.ini.rub.de/?section=gtsdb&subsection=dataset) </br>\n",
    "[Download the Dataset](https://sid.erda.dk/public/archives/ff17dc924eba88d5d01a807357d6614c/published-archive.html)\n",
    "\n",
    "The Train set and gt.txt files were used here.\n",
    "\n",
    "\n",
    "We create a dictionary with the image names as key and annotations + class ID as value. If an image contains multiple objects then the coordinates along with the class is stored as list of lists in the same dictionary's key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T07:42:17.223805512Z",
     "start_time": "2023-11-23T07:42:16.231690584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images: 54188\n"
     ]
    }
   ],
   "source": [
    "txt = np.genfromtxt('russianTrafficSigns/train_labels.txt',delimiter =';', dtype= None,encoding=None)\n",
    "\n",
    "#Creating a dictionary with image names as key and annotations as value\n",
    "dic ={}\n",
    "for i in range (0,len(txt)):\n",
    "    #Image name is first element of annotation file\n",
    "    img_name = txt[i][0]\n",
    "    # 4 Coordinates\n",
    "    target = [txt[i][1],txt[i][2],txt[i][3],txt[i][4],txt[i][5]]\n",
    "    #Last element is the class number\n",
    "    clas = txt[i][-1]\n",
    "    #If multiple objects, store coordinates and classes as list of lists\n",
    "    if(img_name in dic):\n",
    "        dic[img_name].append(target)\n",
    "    else:\n",
    "        dic[img_name] = [target]\n",
    "print(\"Number of Images: \" + str(len(dic)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionary representation:\n",
    "\n",
    "Here we see that the Image with name (key) '00001.ppm' is stored as a list of lists containing the bounding box coordinates as the first 4 elements and the class as the last element."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Distribution\n",
    "\n",
    "From the plot below, it is evident that the distribution of data is not equal. Some classes have very few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T07:42:17.791364942Z",
     "start_time": "2023-11-23T07:42:17.312549882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 20792, 2: 5679, 3: 3576, 4: 10683, 5: 2658, 6: 4979, 7: 61540, 8: 9220, 9: 320, 10: 2781, 11: 30, 12: 1632, 13: 8845, 14: 601, 15: 2333, 16: 294, 17: 2994, 18: 165, 19: 221, 20: 1457, 21: 150, 22: 2278, 23: 4289, 24: 299, 25: 1525, 26: 6188, 27: 421, 28: 430, 29: 496, 30: 565, 31: 127, 32: 2400, 33: 1698, 34: 61, 35: 2049, 36: 82, 37: 59, 38: 661, 39: 712, 40: 1422, 41: 2284, 42: 367, 43: 19412, 44: 306, 45: 545, 46: 1512, 47: 2559, 48: 272, 49: 1147, 50: 303, 51: 143, 52: 1484, 53: 112, 54: 1264, 55: 2503, 56: 724, 57: 558, 58: 683, 59: 5, 60: 913, 61: 265, 62: 532, 63: 1641, 64: 312, 65: 195, 66: 285, 67: 277, 68: 1520, 69: 2103, 70: 142, 71: 2736, 72: 428, 73: 14, 74: 107, 75: 50, 76: 1, 77: 477, 78: 130, 79: 93, 80: 476, 81: 1215, 82: 2574, 83: 109, 84: 81, 85: 522, 86: 541, 87: 569, 88: 225, 89: 301, 90: 43, 91: 176, 92: 1138, 93: 75, 94: 656, 95: 122, 96: 30, 97: 183, 98: 15, 99: 262, 100: 280, 101: 236, 102: 383, 103: 105, 104: 110, 105: 20, 106: 30, 107: 113, 108: 310, 109: 408, 110: 379, 111: 18, 112: 119, 113: 57, 114: 21, 115: 332, 116: 615, 117: 683, 118: 128, 119: 446, 120: 637, 121: 125, 122: 1401, 123: 2, 124: 266, 125: 53, 126: 59, 127: 75, 128: 488, 129: 499, 130: 196, 131: 148, 132: 26, 133: 36, 134: 58, 135: 11, 136: 211, 137: 39, 138: 57, 139: 35, 140: 59, 141: 3, 142: 15, 143: 89, 144: 18, 145: 43, 146: 29, 147: 18, 148: 248, 149: 4, 150: 28, 151: 65, 152: 6, 153: 19, 154: 11, 155: 9}\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Data Distribution\n",
    "\n",
    "cls_lst = {}\n",
    "\n",
    "for i in dic:\n",
    "    for j in dic[i][:]:\n",
    "        #print(len(dic[i]))\n",
    "        for k in range(len(dic[i])):\n",
    "            clss = dic[i][:][k][-1]\n",
    "            if clss in cls_lst:\n",
    "                cls_lst[clss] += 1\n",
    "            else:\n",
    "                cls_lst[clss] = 1\n",
    "                \n",
    "print(cls_lst)\n",
    "\n",
    "xx = []\n",
    "yy = []\n",
    "for i in cls_lst:\n",
    "    xx.append(str(i))\n",
    "    yy.append(cls_lst[i])\n",
    "\n",
    "x_pos = [i for i, _ in enumerate(xx)]\n",
    "\n",
    "plt.bar(x_pos, yy, color='green')\n",
    "plt.xlabel(\"Class Number\")\n",
    "plt.ylabel(\"Number of Examples\")\n",
    "plt.title(\"GTSDB\")\n",
    "#plt.figure(figsize=(30,30))\n",
    "plt.xticks(x_pos, xx)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Organizing the GTSDB Dataset:\n",
    "\n",
    "Unzipping the dataset zip, there are class folders with respective images and .ppm files. There is also the annotation file named as gt.txt\n",
    "\n",
    "I had copied all the .ppm files to a directory named \"train/images\". \n",
    "\n",
    "In the code below, the images that had annotations were only copied to a new folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T07:42:17.792824439Z",
     "start_time": "2023-11-23T07:42:17.790724389Z"
    }
   },
   "outputs": [],
   "source": [
    "# #Copy only files that are annotated in the gt.txt to imagesf\n",
    "# import shutil\n",
    "# \n",
    "# pt = glob('/home/vorkov/Workspace/Python/TrafficSignDetection/experiments/russianTrafficSigns/images/*.jpg')\n",
    "# \n",
    "# len(pt)\n",
    "# #Copying into new directory\n",
    "# for i in range(len(dic)):\n",
    "#     ofile = r'/home/vorkov/Workspace/Python/TrafficSignDetection/experiments/russianTrafficSigns/images/{}'.format(list(dic)[i])\n",
    "#     target = r'/home/vorkov/Workspace/Python/TrafficSignDetection/experiments/russianTrafficSigns/imagesf/{}'.format(list(dic)[i])\n",
    "#     shutil.copyfile(ofile, target)\n",
    "# #Check if len(dic) == number of images in folder\n",
    "# print(len(glob('/home/vorkov/Workspace/Python/TrafficSignDetection/experiments/russianTrafficSigns/imagesf/*.jpg')))\n",
    "# len(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Custom Dataset Class\n",
    "\n",
    "The below code is to get all the required data from the dataset while reading. Here's what happens in the myDataset (torch.utils.data.Dataset) class:\n",
    "\n",
    "1. Initialize all the required variables: Root directory of images (path), transforms (boolean), imgs (images dir in root).\n",
    "2. According to PyTorch's documentation, the Dataset class should implement __getitem__ and __len__ methods. So we declare them.\n",
    "3. In the __getitem__ method, for each image we take the annotations and labels as input from the dictionary we created before. We store them in 'objects' variable.\n",
    "4. A 'targets' dictionary is then initialized to pass all the data to the model while training.\n",
    "5. 'area' declared for the evaluation metrics of COCO API. It separates the metric scores between small, medium and large boxes.</br> 'iscrowd=True' will ignore all instances with numerous objects in one image. </br> 'image_id' is an image identifier. It is unique between all images in the dataset and is used during evaluation.\n",
    "6. 'transforms=True' will call the transforms function to apply transformations.\n",
    "7. __len__ method returns the size of the Dataset.\n",
    "\n",
    "Refer to the [PyTorch's Object Detection Tutorial](https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T07:42:17.928940190Z",
     "start_time": "2023-11-23T07:42:17.926988957Z"
    }
   },
   "outputs": [],
   "source": [
    "class myDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        # load all image files, sorting them to ensure that they are aligned\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"imagesf\"))))\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image path\n",
    "        img_path = os.path.join(self.root, \"imagesf\", self.imgs[idx])\n",
    "        #Load image as PIL\n",
    "        img = Image.open(img_path).convert(\"RGB\")        \n",
    "        # Get objects in the image\n",
    "        objects = dic[self.imgs[idx]]\n",
    "        # Get bounding box coordinates for each object in image\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for obj in objects:\n",
    "            #print(idx, obj[-1], self.imgs)\n",
    "            name = obj[-1]\n",
    "            labels.append(np.int(name))\n",
    "            #Get bounding box coordinates\n",
    "            xmin = np.float(obj[0])\n",
    "            ymin = np.float(obj[1])\n",
    "            xmax = np.float(obj[2])\n",
    "            ymax = np.float(obj[3])\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)        \n",
    " \n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((len(objects),), dtype=torch.int64)\n",
    " \n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    " \n",
    "        if self.transforms is not None:\n",
    "            # Note that target (including bbox) is also transformed\\enhanced here, which is different from transforms from torchvision import\n",
    "            # Https://github.com/pytorch/vision/tree/master/references/detectionOfTransforms.pyThere are examples of target transformations when RandomHorizontalFlip\n",
    "            img, target = self.transforms(img, target)\n",
    " \n",
    "        return img, target\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation using PyTorch's Transforms\n",
    "\n",
    "The images are enhanced before being passed to the network. The images are transformed using the functions defined in the \"transforms.py\" file in [pytorch/vision](https://github.com/pytorch/vision/blob/master/references/detection/transforms.py).\n",
    "\n",
    "The difference between original and transformed images are shown in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T07:42:17.971891609Z",
     "start_time": "2023-11-23T07:42:17.930776218Z"
    }
   },
   "outputs": [],
   "source": [
    "import utilss\n",
    "import transforms as T\n",
    "from engine import train_one_epoch, evaluate\n",
    "# utils, transforms, engine were just downloadedUtils.py,transforms.py,engine.py\n",
    " \n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    # converts the image, a PIL image, into a PyTorch Tensor\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        # during training, randomly flip the training images\n",
    "        # and ground-truth for data augmentation\n",
    "        # 50% chance of flipping horizontally\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    " \n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Training the Model\n",
    "\n",
    "#### Defining the Model and Loading Data\n",
    "\n",
    "1. The number of classes is 44 since there are 43 classes + background\n",
    "2. Then declare train and test dataset by calling the myDataset class which was defined earlier. \n",
    "3. Split the dataset into two 4:1 Train to Test approximately.\n",
    "4. Use PyTorch's DataLoader to load data.\n",
    "5. Define the model. Faster RCNN with a pretrained ResNet50 backbone network is used to finetune according to our dataset.\n",
    "6. Since I had 4 RTX 2080 GPU's available (thanks to my university, Asian Institute of Technology, Thailand and my Machine Learning Professor, Dr. Matthew N. Dailey), I was able to train on all GPUs parallely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T07:42:20.877416515Z",
     "start_time": "2023-11-23T07:42:17.971761958Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vorkov/anaconda/envs/TrafficSignDetection/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/vorkov/anaconda/envs/TrafficSignDetection/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/home/vorkov/anaconda/envs/TrafficSignDetection/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained_backbone' is deprecated since 0.13 and may be removed in the future, please use 'weights_backbone' instead.\n",
      "  warnings.warn(\n",
      "/home/vorkov/anaconda/envs/TrafficSignDetection/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights_backbone' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights_backbone=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights_backbone=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "import utilss\n",
    "import torch.nn as nn\n",
    "os.environ['TORCH_HOME'] = '/home/vorkov/Workspace/Python/TrafficSignDetection/experiments/'\n",
    "\n",
    "root = r'/home/vorkov/Workspace/Python/TrafficSignDetection/experiments/russianTrafficSigns'\n",
    "\n",
    "# Train on the GPU if available else CPU.\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# 44 classes = 43 + background\n",
    "num_classes = 156\n",
    "#Send the data to the myDataset class (Apply transformations, Get bbox, labels, objects)\n",
    "dataset = myDataset(root, get_transform(train=True))\n",
    "dataset_test = myDataset(root, get_transform(train=False))\n",
    "\n",
    "# split the dataset in train and test set\n",
    "# My dataset has 506 images, almost training validation 4:1\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:-100])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[-100:])\n",
    "\n",
    "# define training and validation data loaders\n",
    "#collate_fn returns tuples of images and image annotations for every iteration.\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=2, shuffle=True, # num_workers=4,\n",
    "    collate_fn=utilss.collate_fn)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=2, shuffle=False, # num_workers=4,\n",
    "    collate_fn=utilss.collate_fn)\n",
    "\n",
    "# Define model\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, progress=True, num_classes=num_classes, pretrained_backbone=True)\n",
    "# OR model = get_object_detection_model(num_classes)\n",
    "#model = torch.load('./train150.pkl')\n",
    "\n",
    "#Use specific GPUs:\n",
    "# model = nn.DataParallel(model, device_ids=[0,1,2,3]) #Remove this line if not necessary.\n",
    "\n",
    "# Move the model to device\n",
    "model.to(device)\n",
    "\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Starting the Training\n",
    "\n",
    "1. Defining all the parameters required for training. (Using SGD as optimizer, Cosine Annealing/Decreasing Warm Restarts as learning rate scheduler which decreases the initial learning rate set in a cosine manner until a restart; the lr is set back to the initial lr and the cycle repeats, number of epochs = 1000)\n",
    "2. Declaring all the variable to be retrieved from the COCO Evaluation metrics.\n",
    "3. We start train them model and evaluate the performance on test set.\n",
    "\n",
    "Here, train_one_epoch function in engine.py is used to do the training. The train_one_epoch function returns metric_logger object which we store in 'metrics'. We use the metric_logger's attributes (losses) to append into their respective variables.\n",
    "</br>\n",
    "\n",
    "Then, the evaluate method in CocoEvaluator() in coco_eval.py returns a coco_eval object which is stored in ' _ '. We use this coco_eval object to retrieve the stats attribute from pycocotools' library's summarize(). We append them to all the stat variables to later plot them after training.\n",
    "\n",
    "There is a lot of gibberish of every iteration. Here's the link to jump to next cell: [Next Cell](#plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-23T07:42:20.886601819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [    0/27044]  eta: 11:03:20  lr: 0.000002  loss: 5.7512 (5.7512)  loss_classifier: 5.0415 (5.0415)  loss_box_reg: 0.0121 (0.0121)  loss_objectness: 0.6927 (0.6927)  loss_rpn_box_reg: 0.0050 (0.0050)  time: 1.4717  data: 0.0369  max mem: 2513\n",
      "Epoch: [0]  [   50/27044]  eta: 2:29:10  lr: 0.000052  loss: 5.3718 (5.5805)  loss_classifier: 4.6412 (4.8381)  loss_box_reg: 0.0156 (0.0150)  loss_objectness: 0.6872 (0.6896)  loss_rpn_box_reg: 0.0090 (0.0379)  time: 0.3087  data: 0.0213  max mem: 2686\n",
      "Epoch: [0]  [  100/27044]  eta: 2:23:38  lr: 0.000102  loss: 0.6181 (3.8677)  loss_classifier: 0.2085 (3.1966)  loss_box_reg: 0.0214 (0.0165)  loss_objectness: 0.3839 (0.6186)  loss_rpn_box_reg: 0.0190 (0.0359)  time: 0.3081  data: 0.0193  max mem: 2688\n",
      "Epoch: [0]  [  150/27044]  eta: 2:21:52  lr: 0.000152  loss: 0.2456 (2.7046)  loss_classifier: 0.0787 (2.1849)  loss_box_reg: 0.0096 (0.0177)  loss_objectness: 0.1345 (0.4707)  loss_rpn_box_reg: 0.0133 (0.0313)  time: 0.3087  data: 0.0198  max mem: 2688\n",
      "Epoch: [0]  [  200/27044]  eta: 2:21:00  lr: 0.000202  loss: 0.2748 (2.1058)  loss_classifier: 0.0968 (1.6659)  loss_box_reg: 0.0349 (0.0198)  loss_objectness: 0.0740 (0.3890)  loss_rpn_box_reg: 0.0122 (0.0312)  time: 0.3093  data: 0.0201  max mem: 2688\n",
      "Epoch: [0]  [  250/27044]  eta: 2:20:13  lr: 0.000252  loss: 0.5239 (1.7692)  loss_classifier: 0.2816 (1.3779)  loss_box_reg: 0.1096 (0.0322)  loss_objectness: 0.0706 (0.3299)  loss_rpn_box_reg: 0.0127 (0.0292)  time: 0.3099  data: 0.0211  max mem: 2688\n",
      "Epoch: [0]  [  300/27044]  eta: 2:19:37  lr: 0.000302  loss: 0.4395 (1.5437)  loss_classifier: 0.2478 (1.1861)  loss_box_reg: 0.1194 (0.0428)  loss_objectness: 0.0512 (0.2876)  loss_rpn_box_reg: 0.0112 (0.0272)  time: 0.3089  data: 0.0205  max mem: 2688\n",
      "Epoch: [0]  [  350/27044]  eta: 2:19:04  lr: 0.000352  loss: 0.3364 (1.3782)  loss_classifier: 0.1928 (1.0451)  loss_box_reg: 0.0845 (0.0493)  loss_objectness: 0.0486 (0.2571)  loss_rpn_box_reg: 0.0139 (0.0267)  time: 0.3090  data: 0.0204  max mem: 2688\n",
      "Epoch: [0]  [  400/27044]  eta: 2:18:33  lr: 0.000402  loss: 0.3240 (1.2497)  loss_classifier: 0.1949 (0.9385)  loss_box_reg: 0.0824 (0.0546)  loss_objectness: 0.0395 (0.2314)  loss_rpn_box_reg: 0.0089 (0.0251)  time: 0.3068  data: 0.0184  max mem: 2688\n",
      "Epoch: [0]  [  450/27044]  eta: 2:18:06  lr: 0.000452  loss: 0.2187 (1.1499)  loss_classifier: 0.1233 (0.8550)  loss_box_reg: 0.0541 (0.0582)  loss_objectness: 0.0312 (0.2122)  loss_rpn_box_reg: 0.0091 (0.0245)  time: 0.3075  data: 0.0188  max mem: 2688\n",
      "Epoch: [0]  [  500/27044]  eta: 2:17:44  lr: 0.000501  loss: 0.3408 (1.0717)  loss_classifier: 0.1983 (0.7898)  loss_box_reg: 0.0981 (0.0623)  loss_objectness: 0.0314 (0.1958)  loss_rpn_box_reg: 0.0091 (0.0238)  time: 0.3085  data: 0.0193  max mem: 2688\n",
      "Epoch: [0]  [  550/27044]  eta: 2:17:25  lr: 0.000551  loss: 0.2907 (1.0050)  loss_classifier: 0.1554 (0.7346)  loss_box_reg: 0.0739 (0.0646)  loss_objectness: 0.0341 (0.1822)  loss_rpn_box_reg: 0.0098 (0.0236)  time: 0.3109  data: 0.0216  max mem: 2688\n",
      "Epoch: [0]  [  600/27044]  eta: 2:17:03  lr: 0.000601  loss: 0.2876 (0.9502)  loss_classifier: 0.1717 (0.6887)  loss_box_reg: 0.0827 (0.0670)  loss_objectness: 0.0239 (0.1717)  loss_rpn_box_reg: 0.0072 (0.0228)  time: 0.3069  data: 0.0186  max mem: 2688\n",
      "Epoch: [0]  [  650/27044]  eta: 2:16:42  lr: 0.000651  loss: 0.3350 (0.9048)  loss_classifier: 0.1585 (0.6512)  loss_box_reg: 0.0849 (0.0694)  loss_objectness: 0.0468 (0.1620)  loss_rpn_box_reg: 0.0093 (0.0223)  time: 0.3078  data: 0.0190  max mem: 2688\n",
      "Epoch: [0]  [  700/27044]  eta: 2:16:26  lr: 0.000701  loss: 0.3371 (0.8650)  loss_classifier: 0.2163 (0.6186)  loss_box_reg: 0.1089 (0.0719)  loss_objectness: 0.0204 (0.1528)  loss_rpn_box_reg: 0.0096 (0.0217)  time: 0.3105  data: 0.0215  max mem: 2688\n",
      "Epoch: [0]  [  750/27044]  eta: 2:16:05  lr: 0.000751  loss: 0.3877 (0.8315)  loss_classifier: 0.2223 (0.5910)  loss_box_reg: 0.1309 (0.0748)  loss_objectness: 0.0199 (0.1444)  loss_rpn_box_reg: 0.0094 (0.0213)  time: 0.3075  data: 0.0188  max mem: 2688\n",
      "Epoch: [0]  [  800/27044]  eta: 2:15:48  lr: 0.000801  loss: 0.2465 (0.7975)  loss_classifier: 0.1493 (0.5642)  loss_box_reg: 0.0796 (0.0758)  loss_objectness: 0.0150 (0.1366)  loss_rpn_box_reg: 0.0082 (0.0208)  time: 0.3106  data: 0.0214  max mem: 2688\n",
      "Epoch: [0]  [  850/27044]  eta: 2:15:31  lr: 0.000851  loss: 0.3543 (0.7729)  loss_classifier: 0.1896 (0.5438)  loss_box_reg: 0.1002 (0.0788)  loss_objectness: 0.0176 (0.1300)  loss_rpn_box_reg: 0.0077 (0.0204)  time: 0.3089  data: 0.0197  max mem: 2688\n",
      "Epoch: [0]  [  900/27044]  eta: 2:15:13  lr: 0.000901  loss: 0.3140 (0.7505)  loss_classifier: 0.1453 (0.5246)  loss_box_reg: 0.1148 (0.0813)  loss_objectness: 0.0179 (0.1244)  loss_rpn_box_reg: 0.0149 (0.0203)  time: 0.3085  data: 0.0196  max mem: 2688\n",
      "Epoch: [0]  [  950/27044]  eta: 2:14:58  lr: 0.000951  loss: 0.4193 (0.7300)  loss_classifier: 0.2466 (0.5073)  loss_box_reg: 0.1470 (0.0833)  loss_objectness: 0.0158 (0.1191)  loss_rpn_box_reg: 0.0134 (0.0203)  time: 0.3106  data: 0.0211  max mem: 2688\n",
      "Epoch: [0]  [ 1000/27044]  eta: 2:14:42  lr: 0.001000  loss: 0.2465 (0.7106)  loss_classifier: 0.1547 (0.4908)  loss_box_reg: 0.0835 (0.0847)  loss_objectness: 0.0142 (0.1149)  loss_rpn_box_reg: 0.0073 (0.0203)  time: 0.3090  data: 0.0196  max mem: 2688\n",
      "Epoch: [0]  [ 1050/27044]  eta: 2:14:29  lr: 0.001000  loss: 0.3879 (0.6950)  loss_classifier: 0.1761 (0.4772)  loss_box_reg: 0.1490 (0.0871)  loss_objectness: 0.0164 (0.1105)  loss_rpn_box_reg: 0.0131 (0.0202)  time: 0.3120  data: 0.0221  max mem: 2688\n",
      "Epoch: [0]  [ 1100/27044]  eta: 2:14:13  lr: 0.001000  loss: 0.3742 (0.6816)  loss_classifier: 0.2068 (0.4654)  loss_box_reg: 0.1150 (0.0895)  loss_objectness: 0.0169 (0.1068)  loss_rpn_box_reg: 0.0052 (0.0199)  time: 0.3084  data: 0.0185  max mem: 2688\n",
      "Epoch: [0]  [ 1150/27044]  eta: 2:13:59  lr: 0.001000  loss: 0.3652 (0.6672)  loss_classifier: 0.2112 (0.4535)  loss_box_reg: 0.1333 (0.0910)  loss_objectness: 0.0168 (0.1029)  loss_rpn_box_reg: 0.0066 (0.0196)  time: 0.3092  data: 0.0192  max mem: 2688\n",
      "Epoch: [0]  [ 1200/27044]  eta: 2:13:43  lr: 0.001000  loss: 0.2636 (0.6526)  loss_classifier: 0.1373 (0.4416)  loss_box_reg: 0.1009 (0.0924)  loss_objectness: 0.0103 (0.0994)  loss_rpn_box_reg: 0.0067 (0.0194)  time: 0.3091  data: 0.0200  max mem: 2688\n",
      "Epoch: [0]  [ 1250/27044]  eta: 2:13:25  lr: 0.001000  loss: 0.3283 (0.6411)  loss_classifier: 0.1638 (0.4316)  loss_box_reg: 0.1259 (0.0940)  loss_objectness: 0.0164 (0.0964)  loss_rpn_box_reg: 0.0093 (0.0191)  time: 0.3100  data: 0.0205  max mem: 2688\n",
      "Epoch: [0]  [ 1300/27044]  eta: 2:13:08  lr: 0.001000  loss: 0.3777 (0.6321)  loss_classifier: 0.1895 (0.4236)  loss_box_reg: 0.1660 (0.0963)  loss_objectness: 0.0157 (0.0933)  loss_rpn_box_reg: 0.0093 (0.0189)  time: 0.3100  data: 0.0214  max mem: 2688\n",
      "Epoch: [0]  [ 1350/27044]  eta: 2:12:53  lr: 0.001000  loss: 0.2886 (0.6210)  loss_classifier: 0.1467 (0.4145)  loss_box_reg: 0.1090 (0.0975)  loss_objectness: 0.0089 (0.0905)  loss_rpn_box_reg: 0.0045 (0.0186)  time: 0.3097  data: 0.0206  max mem: 2688\n",
      "Epoch: [0]  [ 1400/27044]  eta: 2:12:36  lr: 0.001000  loss: 0.3168 (0.6104)  loss_classifier: 0.1651 (0.4057)  loss_box_reg: 0.1352 (0.0985)  loss_objectness: 0.0118 (0.0878)  loss_rpn_box_reg: 0.0107 (0.0184)  time: 0.3106  data: 0.0215  max mem: 2688\n",
      "Epoch: [0]  [ 1450/27044]  eta: 2:12:22  lr: 0.001000  loss: 0.3049 (0.6023)  loss_classifier: 0.1533 (0.3983)  loss_box_reg: 0.1271 (0.0997)  loss_objectness: 0.0126 (0.0859)  loss_rpn_box_reg: 0.0081 (0.0183)  time: 0.3105  data: 0.0210  max mem: 2688\n",
      "Epoch: [0]  [ 1500/27044]  eta: 2:12:07  lr: 0.001000  loss: 0.3176 (0.5948)  loss_classifier: 0.1550 (0.3917)  loss_box_reg: 0.1135 (0.1010)  loss_objectness: 0.0075 (0.0838)  loss_rpn_box_reg: 0.0060 (0.0182)  time: 0.3140  data: 0.0238  max mem: 2688\n",
      "Epoch: [0]  [ 1550/27044]  eta: 2:11:54  lr: 0.001000  loss: 0.3233 (0.5868)  loss_classifier: 0.1585 (0.3849)  loss_box_reg: 0.1396 (0.1023)  loss_objectness: 0.0069 (0.0816)  loss_rpn_box_reg: 0.0073 (0.0180)  time: 0.3106  data: 0.0217  max mem: 2688\n",
      "Epoch: [0]  [ 1600/27044]  eta: 2:11:38  lr: 0.001000  loss: 0.2975 (0.5786)  loss_classifier: 0.1256 (0.3777)  loss_box_reg: 0.1306 (0.1035)  loss_objectness: 0.0130 (0.0796)  loss_rpn_box_reg: 0.0103 (0.0178)  time: 0.3107  data: 0.0219  max mem: 2688\n",
      "Epoch: [0]  [ 1650/27044]  eta: 2:11:20  lr: 0.001000  loss: 0.4057 (0.5722)  loss_classifier: 0.1937 (0.3722)  loss_box_reg: 0.1315 (0.1047)  loss_objectness: 0.0135 (0.0778)  loss_rpn_box_reg: 0.0092 (0.0176)  time: 0.3065  data: 0.0178  max mem: 2688\n",
      "Epoch: [0]  [ 1700/27044]  eta: 2:11:05  lr: 0.001000  loss: 0.2721 (0.5650)  loss_classifier: 0.1269 (0.3659)  loss_box_reg: 0.1062 (0.1054)  loss_objectness: 0.0096 (0.0761)  loss_rpn_box_reg: 0.0076 (0.0177)  time: 0.3111  data: 0.0221  max mem: 2688\n",
      "Epoch: [0]  [ 1750/27044]  eta: 2:10:48  lr: 0.001000  loss: 0.2385 (0.5574)  loss_classifier: 0.1315 (0.3598)  loss_box_reg: 0.1035 (0.1061)  loss_objectness: 0.0064 (0.0742)  loss_rpn_box_reg: 0.0046 (0.0174)  time: 0.3100  data: 0.0207  max mem: 2688\n",
      "Epoch: [0]  [ 1800/27044]  eta: 2:10:32  lr: 0.001000  loss: 0.3027 (0.5522)  loss_classifier: 0.1663 (0.3549)  loss_box_reg: 0.1496 (0.1074)  loss_objectness: 0.0078 (0.0725)  loss_rpn_box_reg: 0.0083 (0.0173)  time: 0.3079  data: 0.0194  max mem: 2688\n",
      "Epoch: [0]  [ 1850/27044]  eta: 2:10:15  lr: 0.001000  loss: 0.2192 (0.5458)  loss_classifier: 0.0934 (0.3495)  loss_box_reg: 0.1146 (0.1083)  loss_objectness: 0.0096 (0.0708)  loss_rpn_box_reg: 0.0087 (0.0171)  time: 0.3071  data: 0.0181  max mem: 2688\n",
      "Epoch: [0]  [ 1900/27044]  eta: 2:09:59  lr: 0.001000  loss: 0.3123 (0.5407)  loss_classifier: 0.1794 (0.3450)  loss_box_reg: 0.1228 (0.1092)  loss_objectness: 0.0071 (0.0693)  loss_rpn_box_reg: 0.0076 (0.0172)  time: 0.3094  data: 0.0203  max mem: 2688\n",
      "Epoch: [0]  [ 1950/27044]  eta: 2:09:44  lr: 0.001000  loss: 0.2774 (0.5353)  loss_classifier: 0.1502 (0.3405)  loss_box_reg: 0.1073 (0.1097)  loss_objectness: 0.0126 (0.0681)  loss_rpn_box_reg: 0.0079 (0.0171)  time: 0.3100  data: 0.0207  max mem: 2688\n",
      "Epoch: [0]  [ 2000/27044]  eta: 2:09:28  lr: 0.001000  loss: 0.3128 (0.5301)  loss_classifier: 0.1738 (0.3360)  loss_box_reg: 0.1260 (0.1103)  loss_objectness: 0.0092 (0.0667)  loss_rpn_box_reg: 0.0068 (0.0170)  time: 0.3101  data: 0.0209  max mem: 2688\n",
      "Epoch: [0]  [ 2050/27044]  eta: 2:09:12  lr: 0.001000  loss: 0.2837 (0.5255)  loss_classifier: 0.1335 (0.3320)  loss_box_reg: 0.1228 (0.1110)  loss_objectness: 0.0104 (0.0657)  loss_rpn_box_reg: 0.0052 (0.0168)  time: 0.3083  data: 0.0187  max mem: 2688\n",
      "Epoch: [0]  [ 2100/27044]  eta: 2:08:57  lr: 0.001000  loss: 0.2488 (0.5201)  loss_classifier: 0.1169 (0.3275)  loss_box_reg: 0.1128 (0.1115)  loss_objectness: 0.0081 (0.0645)  loss_rpn_box_reg: 0.0032 (0.0166)  time: 0.3110  data: 0.0213  max mem: 2688\n",
      "Epoch: [0]  [ 2150/27044]  eta: 2:08:42  lr: 0.001000  loss: 0.2227 (0.5146)  loss_classifier: 0.1206 (0.3232)  loss_box_reg: 0.0927 (0.1117)  loss_objectness: 0.0106 (0.0633)  loss_rpn_box_reg: 0.0059 (0.0165)  time: 0.3109  data: 0.0213  max mem: 2688\n",
      "Epoch: [0]  [ 2200/27044]  eta: 2:08:37  lr: 0.001000  loss: 0.2511 (0.5107)  loss_classifier: 0.1303 (0.3195)  loss_box_reg: 0.1224 (0.1126)  loss_objectness: 0.0085 (0.0622)  loss_rpn_box_reg: 0.0064 (0.0164)  time: 0.3259  data: 0.0240  max mem: 2688\n",
      "Epoch: [0]  [ 2250/27044]  eta: 2:08:30  lr: 0.001000  loss: 0.3367 (0.5065)  loss_classifier: 0.1737 (0.3160)  loss_box_reg: 0.1400 (0.1131)  loss_objectness: 0.0119 (0.0611)  loss_rpn_box_reg: 0.0075 (0.0162)  time: 0.3346  data: 0.0266  max mem: 2688\n",
      "Epoch: [0]  [ 2300/27044]  eta: 2:08:20  lr: 0.001000  loss: 0.2591 (0.5025)  loss_classifier: 0.1018 (0.3126)  loss_box_reg: 0.1195 (0.1137)  loss_objectness: 0.0112 (0.0601)  loss_rpn_box_reg: 0.0052 (0.0161)  time: 0.3147  data: 0.0214  max mem: 2688\n",
      "Epoch: [0]  [ 2350/27044]  eta: 2:08:10  lr: 0.001000  loss: 0.2634 (0.4980)  loss_classifier: 0.1128 (0.3090)  loss_box_reg: 0.1247 (0.1139)  loss_objectness: 0.0132 (0.0591)  loss_rpn_box_reg: 0.0110 (0.0160)  time: 0.3330  data: 0.0238  max mem: 2688\n",
      "Epoch: [0]  [ 2400/27044]  eta: 2:07:59  lr: 0.001000  loss: 0.3301 (0.4940)  loss_classifier: 0.1542 (0.3056)  loss_box_reg: 0.1458 (0.1143)  loss_objectness: 0.0090 (0.0581)  loss_rpn_box_reg: 0.0053 (0.0159)  time: 0.3238  data: 0.0230  max mem: 2688\n",
      "Epoch: [0]  [ 2450/27044]  eta: 2:07:44  lr: 0.001000  loss: 0.3121 (0.4908)  loss_classifier: 0.1592 (0.3029)  loss_box_reg: 0.1186 (0.1149)  loss_objectness: 0.0084 (0.0572)  loss_rpn_box_reg: 0.0044 (0.0158)  time: 0.3117  data: 0.0185  max mem: 2688\n",
      "Epoch: [0]  [ 2500/27044]  eta: 2:07:30  lr: 0.001000  loss: 0.2648 (0.4877)  loss_classifier: 0.1285 (0.2999)  loss_box_reg: 0.1237 (0.1155)  loss_objectness: 0.0086 (0.0566)  loss_rpn_box_reg: 0.0062 (0.0158)  time: 0.3107  data: 0.0202  max mem: 2688\n",
      "Epoch: [0]  [ 2550/27044]  eta: 2:07:14  lr: 0.001000  loss: 0.2647 (0.4852)  loss_classifier: 0.1208 (0.2976)  loss_box_reg: 0.1087 (0.1162)  loss_objectness: 0.0035 (0.0558)  loss_rpn_box_reg: 0.0055 (0.0156)  time: 0.3095  data: 0.0199  max mem: 2688\n",
      "Epoch: [0]  [ 2600/27044]  eta: 2:07:03  lr: 0.001000  loss: 0.3093 (0.4827)  loss_classifier: 0.1181 (0.2952)  loss_box_reg: 0.1394 (0.1170)  loss_objectness: 0.0068 (0.0549)  loss_rpn_box_reg: 0.0071 (0.0155)  time: 0.3237  data: 0.0242  max mem: 2688\n",
      "Epoch: [0]  [ 2650/27044]  eta: 2:06:46  lr: 0.001000  loss: 0.3236 (0.4791)  loss_classifier: 0.1396 (0.2923)  loss_box_reg: 0.1238 (0.1172)  loss_objectness: 0.0057 (0.0542)  loss_rpn_box_reg: 0.0058 (0.0155)  time: 0.3087  data: 0.0198  max mem: 2688\n",
      "Epoch: [0]  [ 2700/27044]  eta: 2:06:29  lr: 0.001000  loss: 0.2982 (0.4768)  loss_classifier: 0.1526 (0.2902)  loss_box_reg: 0.1367 (0.1179)  loss_objectness: 0.0051 (0.0533)  loss_rpn_box_reg: 0.0053 (0.0153)  time: 0.3072  data: 0.0188  max mem: 2688\n",
      "Epoch: [0]  [ 2750/27044]  eta: 2:06:13  lr: 0.001000  loss: 0.3106 (0.4741)  loss_classifier: 0.1541 (0.2880)  loss_box_reg: 0.1012 (0.1183)  loss_objectness: 0.0114 (0.0526)  loss_rpn_box_reg: 0.0044 (0.0152)  time: 0.3108  data: 0.0217  max mem: 2688\n",
      "Epoch: [0]  [ 2800/27044]  eta: 2:05:56  lr: 0.001000  loss: 0.2726 (0.4715)  loss_classifier: 0.1228 (0.2856)  loss_box_reg: 0.1014 (0.1188)  loss_objectness: 0.0083 (0.0519)  loss_rpn_box_reg: 0.0057 (0.0151)  time: 0.3082  data: 0.0197  max mem: 2688\n",
      "Epoch: [0]  [ 2850/27044]  eta: 2:05:41  lr: 0.001000  loss: 0.2134 (0.4684)  loss_classifier: 0.1051 (0.2831)  loss_box_reg: 0.1000 (0.1189)  loss_objectness: 0.0069 (0.0513)  loss_rpn_box_reg: 0.0053 (0.0151)  time: 0.3111  data: 0.0191  max mem: 2688\n",
      "Epoch: [0]  [ 2900/27044]  eta: 2:05:27  lr: 0.001000  loss: 0.3043 (0.4662)  loss_classifier: 0.1422 (0.2811)  loss_box_reg: 0.1261 (0.1193)  loss_objectness: 0.0139 (0.0506)  loss_rpn_box_reg: 0.0054 (0.0150)  time: 0.3115  data: 0.0225  max mem: 2688\n",
      "Epoch: [0]  [ 2950/27044]  eta: 2:05:12  lr: 0.001000  loss: 0.2500 (0.4632)  loss_classifier: 0.1049 (0.2786)  loss_box_reg: 0.1069 (0.1196)  loss_objectness: 0.0106 (0.0500)  loss_rpn_box_reg: 0.0060 (0.0149)  time: 0.3150  data: 0.0223  max mem: 2688\n",
      "Epoch: [0]  [ 3000/27044]  eta: 2:04:58  lr: 0.001000  loss: 0.2435 (0.4609)  loss_classifier: 0.1072 (0.2765)  loss_box_reg: 0.1191 (0.1202)  loss_objectness: 0.0053 (0.0494)  loss_rpn_box_reg: 0.0037 (0.0148)  time: 0.3223  data: 0.0242  max mem: 2688\n",
      "Epoch: [0]  [ 3050/27044]  eta: 2:04:42  lr: 0.001000  loss: 0.2436 (0.4583)  loss_classifier: 0.1146 (0.2745)  loss_box_reg: 0.0989 (0.1203)  loss_objectness: 0.0047 (0.0488)  loss_rpn_box_reg: 0.0053 (0.0147)  time: 0.3098  data: 0.0203  max mem: 2688\n",
      "Epoch: [0]  [ 3100/27044]  eta: 2:04:26  lr: 0.001000  loss: 0.2968 (0.4562)  loss_classifier: 0.1760 (0.2726)  loss_box_reg: 0.1424 (0.1206)  loss_objectness: 0.0134 (0.0485)  loss_rpn_box_reg: 0.0056 (0.0147)  time: 0.3083  data: 0.0195  max mem: 2688\n",
      "Epoch: [0]  [ 3150/27044]  eta: 2:04:10  lr: 0.001000  loss: 0.2364 (0.4540)  loss_classifier: 0.0886 (0.2707)  loss_box_reg: 0.1159 (0.1210)  loss_objectness: 0.0054 (0.0478)  loss_rpn_box_reg: 0.0056 (0.0145)  time: 0.3093  data: 0.0206  max mem: 2688\n",
      "Epoch: [0]  [ 3200/27044]  eta: 2:03:54  lr: 0.001000  loss: 0.3329 (0.4521)  loss_classifier: 0.1411 (0.2688)  loss_box_reg: 0.1530 (0.1213)  loss_objectness: 0.0112 (0.0475)  loss_rpn_box_reg: 0.0076 (0.0145)  time: 0.3133  data: 0.0211  max mem: 2688\n",
      "Epoch: [0]  [ 3250/27044]  eta: 2:03:37  lr: 0.001000  loss: 0.2350 (0.4495)  loss_classifier: 0.0967 (0.2667)  loss_box_reg: 0.0904 (0.1213)  loss_objectness: 0.0144 (0.0471)  loss_rpn_box_reg: 0.0069 (0.0144)  time: 0.3072  data: 0.0181  max mem: 2688\n",
      "Epoch: [0]  [ 3300/27044]  eta: 2:03:21  lr: 0.001000  loss: 0.2302 (0.4476)  loss_classifier: 0.1133 (0.2650)  loss_box_reg: 0.1065 (0.1216)  loss_objectness: 0.0064 (0.0466)  loss_rpn_box_reg: 0.0042 (0.0144)  time: 0.3101  data: 0.0201  max mem: 2688\n",
      "Epoch: [0]  [ 3350/27044]  eta: 2:03:05  lr: 0.001000  loss: 0.2364 (0.4453)  loss_classifier: 0.1052 (0.2631)  loss_box_reg: 0.1045 (0.1218)  loss_objectness: 0.0054 (0.0461)  loss_rpn_box_reg: 0.0040 (0.0143)  time: 0.3100  data: 0.0198  max mem: 2688\n",
      "Epoch: [0]  [ 3400/27044]  eta: 2:02:51  lr: 0.001000  loss: 0.2512 (0.4433)  loss_classifier: 0.1292 (0.2615)  loss_box_reg: 0.1192 (0.1220)  loss_objectness: 0.0062 (0.0455)  loss_rpn_box_reg: 0.0058 (0.0142)  time: 0.3117  data: 0.0212  max mem: 2688\n",
      "Epoch: [0]  [ 3450/27044]  eta: 2:02:36  lr: 0.001000  loss: 0.2423 (0.4409)  loss_classifier: 0.1203 (0.2596)  loss_box_reg: 0.1252 (0.1221)  loss_objectness: 0.0053 (0.0450)  loss_rpn_box_reg: 0.0043 (0.0142)  time: 0.3099  data: 0.0200  max mem: 2688\n",
      "Epoch: [0]  [ 3500/27044]  eta: 2:02:21  lr: 0.001000  loss: 0.2949 (0.4392)  loss_classifier: 0.1300 (0.2581)  loss_box_reg: 0.1416 (0.1225)  loss_objectness: 0.0061 (0.0445)  loss_rpn_box_reg: 0.0035 (0.0140)  time: 0.3146  data: 0.0222  max mem: 2688\n",
      "Epoch: [0]  [ 3550/27044]  eta: 2:02:06  lr: 0.001000  loss: 0.2617 (0.4371)  loss_classifier: 0.1261 (0.2565)  loss_box_reg: 0.1132 (0.1226)  loss_objectness: 0.0036 (0.0440)  loss_rpn_box_reg: 0.0042 (0.0140)  time: 0.3155  data: 0.0218  max mem: 2688\n",
      "Epoch: [0]  [ 3600/27044]  eta: 2:01:51  lr: 0.001000  loss: 0.2787 (0.4353)  loss_classifier: 0.1305 (0.2551)  loss_box_reg: 0.1030 (0.1229)  loss_objectness: 0.0062 (0.0435)  loss_rpn_box_reg: 0.0052 (0.0139)  time: 0.3169  data: 0.0244  max mem: 2688\n",
      "Epoch: [0]  [ 3650/27044]  eta: 2:01:36  lr: 0.001000  loss: 0.3025 (0.4336)  loss_classifier: 0.1252 (0.2535)  loss_box_reg: 0.1311 (0.1230)  loss_objectness: 0.0106 (0.0431)  loss_rpn_box_reg: 0.0103 (0.0139)  time: 0.3117  data: 0.0224  max mem: 2688\n",
      "Epoch: [0]  [ 3700/27044]  eta: 2:01:20  lr: 0.001000  loss: 0.2363 (0.4317)  loss_classifier: 0.1166 (0.2521)  loss_box_reg: 0.1025 (0.1232)  loss_objectness: 0.0040 (0.0427)  loss_rpn_box_reg: 0.0034 (0.0138)  time: 0.3114  data: 0.0190  max mem: 2688\n",
      "Epoch: [0]  [ 3750/27044]  eta: 2:01:04  lr: 0.001000  loss: 0.2986 (0.4303)  loss_classifier: 0.1373 (0.2506)  loss_box_reg: 0.1333 (0.1237)  loss_objectness: 0.0082 (0.0422)  loss_rpn_box_reg: 0.0064 (0.0137)  time: 0.3087  data: 0.0194  max mem: 2688\n",
      "Epoch: [0]  [ 3800/27044]  eta: 2:00:49  lr: 0.001000  loss: 0.1884 (0.4284)  loss_classifier: 0.0924 (0.2492)  loss_box_reg: 0.1029 (0.1238)  loss_objectness: 0.0070 (0.0418)  loss_rpn_box_reg: 0.0062 (0.0137)  time: 0.3119  data: 0.0201  max mem: 2688\n",
      "Epoch: [0]  [ 3850/27044]  eta: 2:00:36  lr: 0.001000  loss: 0.2564 (0.4267)  loss_classifier: 0.1197 (0.2479)  loss_box_reg: 0.1175 (0.1238)  loss_objectness: 0.0090 (0.0414)  loss_rpn_box_reg: 0.0053 (0.0136)  time: 0.3250  data: 0.0288  max mem: 2688\n",
      "Epoch: [0]  [ 3900/27044]  eta: 2:00:21  lr: 0.001000  loss: 0.2281 (0.4246)  loss_classifier: 0.0922 (0.2464)  loss_box_reg: 0.0969 (0.1238)  loss_objectness: 0.0047 (0.0409)  loss_rpn_box_reg: 0.0059 (0.0135)  time: 0.3130  data: 0.0219  max mem: 2688\n",
      "Epoch: [0]  [ 3950/27044]  eta: 2:00:07  lr: 0.001000  loss: 0.2276 (0.4228)  loss_classifier: 0.0942 (0.2449)  loss_box_reg: 0.1026 (0.1238)  loss_objectness: 0.0129 (0.0406)  loss_rpn_box_reg: 0.0080 (0.0135)  time: 0.3162  data: 0.0243  max mem: 2688\n",
      "Epoch: [0]  [ 4000/27044]  eta: 1:59:52  lr: 0.001000  loss: 0.2631 (0.4211)  loss_classifier: 0.1313 (0.2435)  loss_box_reg: 0.1046 (0.1239)  loss_objectness: 0.0078 (0.0402)  loss_rpn_box_reg: 0.0062 (0.0134)  time: 0.3144  data: 0.0234  max mem: 2688\n",
      "Epoch: [0]  [ 4050/27044]  eta: 1:59:37  lr: 0.001000  loss: 0.2093 (0.4192)  loss_classifier: 0.1044 (0.2421)  loss_box_reg: 0.0899 (0.1239)  loss_objectness: 0.0033 (0.0398)  loss_rpn_box_reg: 0.0036 (0.0134)  time: 0.3140  data: 0.0232  max mem: 2688\n",
      "Epoch: [0]  [ 4100/27044]  eta: 1:59:23  lr: 0.001000  loss: 0.2683 (0.4175)  loss_classifier: 0.1354 (0.2407)  loss_box_reg: 0.1171 (0.1240)  loss_objectness: 0.0038 (0.0395)  loss_rpn_box_reg: 0.0036 (0.0133)  time: 0.3156  data: 0.0241  max mem: 2688\n",
      "Epoch: [0]  [ 4150/27044]  eta: 1:59:09  lr: 0.001000  loss: 0.2355 (0.4159)  loss_classifier: 0.1172 (0.2395)  loss_box_reg: 0.1309 (0.1240)  loss_objectness: 0.0072 (0.0391)  loss_rpn_box_reg: 0.0055 (0.0132)  time: 0.3243  data: 0.0276  max mem: 2688\n",
      "Epoch: [0]  [ 4200/27044]  eta: 1:58:55  lr: 0.001000  loss: 0.2432 (0.4143)  loss_classifier: 0.1194 (0.2383)  loss_box_reg: 0.1041 (0.1241)  loss_objectness: 0.0046 (0.0387)  loss_rpn_box_reg: 0.0036 (0.0132)  time: 0.3150  data: 0.0239  max mem: 2688\n",
      "Epoch: [0]  [ 4250/27044]  eta: 1:58:40  lr: 0.001000  loss: 0.2408 (0.4125)  loss_classifier: 0.1081 (0.2370)  loss_box_reg: 0.1042 (0.1241)  loss_objectness: 0.0031 (0.0384)  loss_rpn_box_reg: 0.0048 (0.0131)  time: 0.3140  data: 0.0232  max mem: 2688\n",
      "Epoch: [0]  [ 4300/27044]  eta: 1:58:25  lr: 0.001000  loss: 0.3086 (0.4109)  loss_classifier: 0.1021 (0.2356)  loss_box_reg: 0.1278 (0.1242)  loss_objectness: 0.0050 (0.0380)  loss_rpn_box_reg: 0.0056 (0.0131)  time: 0.3132  data: 0.0219  max mem: 2688\n",
      "Epoch: [0]  [ 4350/27044]  eta: 1:58:10  lr: 0.001000  loss: 0.2610 (0.4095)  loss_classifier: 0.1098 (0.2345)  loss_box_reg: 0.1288 (0.1243)  loss_objectness: 0.0043 (0.0377)  loss_rpn_box_reg: 0.0075 (0.0130)  time: 0.3157  data: 0.0245  max mem: 2688\n",
      "Epoch: [0]  [ 4400/27044]  eta: 1:57:55  lr: 0.001000  loss: 0.2121 (0.4079)  loss_classifier: 0.0918 (0.2334)  loss_box_reg: 0.0905 (0.1242)  loss_objectness: 0.0061 (0.0373)  loss_rpn_box_reg: 0.0051 (0.0129)  time: 0.3111  data: 0.0201  max mem: 2688\n",
      "Epoch: [0]  [ 4450/27044]  eta: 1:57:40  lr: 0.001000  loss: 0.2130 (0.4068)  loss_classifier: 0.1030 (0.2324)  loss_box_reg: 0.0873 (0.1244)  loss_objectness: 0.0076 (0.0370)  loss_rpn_box_reg: 0.0058 (0.0129)  time: 0.3127  data: 0.0221  max mem: 2688\n",
      "Epoch: [0]  [ 4500/27044]  eta: 1:57:25  lr: 0.001000  loss: 0.2916 (0.4054)  loss_classifier: 0.1456 (0.2313)  loss_box_reg: 0.1293 (0.1245)  loss_objectness: 0.0086 (0.0367)  loss_rpn_box_reg: 0.0045 (0.0128)  time: 0.3147  data: 0.0233  max mem: 2688\n",
      "Epoch: [0]  [ 4550/27044]  eta: 1:57:10  lr: 0.001000  loss: 0.2173 (0.4040)  loss_classifier: 0.1052 (0.2303)  loss_box_reg: 0.0963 (0.1245)  loss_objectness: 0.0059 (0.0364)  loss_rpn_box_reg: 0.0048 (0.0128)  time: 0.3155  data: 0.0246  max mem: 2688\n",
      "Epoch: [0]  [ 4600/27044]  eta: 1:56:55  lr: 0.001000  loss: 0.2432 (0.4023)  loss_classifier: 0.1078 (0.2291)  loss_box_reg: 0.1105 (0.1244)  loss_objectness: 0.0054 (0.0361)  loss_rpn_box_reg: 0.0054 (0.0127)  time: 0.3171  data: 0.0254  max mem: 2688\n",
      "Epoch: [0]  [ 4650/27044]  eta: 1:56:40  lr: 0.001000  loss: 0.2203 (0.4010)  loss_classifier: 0.1029 (0.2281)  loss_box_reg: 0.1192 (0.1245)  loss_objectness: 0.0048 (0.0358)  loss_rpn_box_reg: 0.0048 (0.0127)  time: 0.3181  data: 0.0261  max mem: 2688\n",
      "Epoch: [0]  [ 4700/27044]  eta: 1:56:25  lr: 0.001000  loss: 0.2177 (0.4000)  loss_classifier: 0.0813 (0.2272)  loss_box_reg: 0.1140 (0.1247)  loss_objectness: 0.0031 (0.0355)  loss_rpn_box_reg: 0.0029 (0.0126)  time: 0.3147  data: 0.0228  max mem: 2688\n",
      "Epoch: [0]  [ 4750/27044]  eta: 1:56:10  lr: 0.001000  loss: 0.2468 (0.3986)  loss_classifier: 0.1100 (0.2261)  loss_box_reg: 0.1059 (0.1248)  loss_objectness: 0.0033 (0.0352)  loss_rpn_box_reg: 0.0032 (0.0125)  time: 0.3176  data: 0.0265  max mem: 2688\n",
      "Epoch: [0]  [ 4800/27044]  eta: 1:55:55  lr: 0.001000  loss: 0.1866 (0.3971)  loss_classifier: 0.1082 (0.2250)  loss_box_reg: 0.0705 (0.1247)  loss_objectness: 0.0043 (0.0349)  loss_rpn_box_reg: 0.0038 (0.0125)  time: 0.3150  data: 0.0234  max mem: 2688\n",
      "Epoch: [0]  [ 4850/27044]  eta: 1:55:40  lr: 0.001000  loss: 0.1866 (0.3956)  loss_classifier: 0.0773 (0.2238)  loss_box_reg: 0.0879 (0.1247)  loss_objectness: 0.0028 (0.0346)  loss_rpn_box_reg: 0.0029 (0.0124)  time: 0.3142  data: 0.0233  max mem: 2688\n",
      "Epoch: [0]  [ 4900/27044]  eta: 1:55:24  lr: 0.001000  loss: 0.2047 (0.3941)  loss_classifier: 0.0967 (0.2227)  loss_box_reg: 0.0955 (0.1246)  loss_objectness: 0.0027 (0.0343)  loss_rpn_box_reg: 0.0030 (0.0124)  time: 0.3135  data: 0.0226  max mem: 2688\n",
      "Epoch: [0]  [ 4950/27044]  eta: 1:55:09  lr: 0.001000  loss: 0.2140 (0.3927)  loss_classifier: 0.0883 (0.2217)  loss_box_reg: 0.0963 (0.1246)  loss_objectness: 0.0041 (0.0341)  loss_rpn_box_reg: 0.0073 (0.0123)  time: 0.3139  data: 0.0221  max mem: 2688\n",
      "Epoch: [0]  [ 5000/27044]  eta: 1:54:54  lr: 0.001000  loss: 0.2798 (0.3916)  loss_classifier: 0.0889 (0.2208)  loss_box_reg: 0.1092 (0.1246)  loss_objectness: 0.0105 (0.0338)  loss_rpn_box_reg: 0.0039 (0.0123)  time: 0.3171  data: 0.0253  max mem: 2688\n",
      "Epoch: [0]  [ 5050/27044]  eta: 1:54:39  lr: 0.001000  loss: 0.2459 (0.3905)  loss_classifier: 0.1019 (0.2199)  loss_box_reg: 0.1365 (0.1247)  loss_objectness: 0.0036 (0.0336)  loss_rpn_box_reg: 0.0044 (0.0123)  time: 0.3162  data: 0.0246  max mem: 2688\n",
      "Epoch: [0]  [ 5100/27044]  eta: 1:54:25  lr: 0.001000  loss: 0.2106 (0.3894)  loss_classifier: 0.0816 (0.2190)  loss_box_reg: 0.0845 (0.1248)  loss_objectness: 0.0069 (0.0333)  loss_rpn_box_reg: 0.0055 (0.0123)  time: 0.3188  data: 0.0273  max mem: 2688\n",
      "Epoch: [0]  [ 5150/27044]  eta: 1:54:09  lr: 0.001000  loss: 0.2816 (0.3886)  loss_classifier: 0.1050 (0.2183)  loss_box_reg: 0.1251 (0.1250)  loss_objectness: 0.0051 (0.0331)  loss_rpn_box_reg: 0.0035 (0.0122)  time: 0.3131  data: 0.0217  max mem: 2688\n",
      "Epoch: [0]  [ 5200/27044]  eta: 1:53:54  lr: 0.001000  loss: 0.2120 (0.3875)  loss_classifier: 0.1051 (0.2175)  loss_box_reg: 0.1023 (0.1250)  loss_objectness: 0.0012 (0.0328)  loss_rpn_box_reg: 0.0024 (0.0122)  time: 0.3111  data: 0.0201  max mem: 2688\n",
      "Epoch: [0]  [ 5250/27044]  eta: 1:53:38  lr: 0.001000  loss: 0.3015 (0.3867)  loss_classifier: 0.1481 (0.2168)  loss_box_reg: 0.1548 (0.1251)  loss_objectness: 0.0044 (0.0326)  loss_rpn_box_reg: 0.0033 (0.0122)  time: 0.3138  data: 0.0228  max mem: 2688\n",
      "Epoch: [0]  [ 5300/27044]  eta: 1:53:23  lr: 0.001000  loss: 0.2594 (0.3856)  loss_classifier: 0.1226 (0.2159)  loss_box_reg: 0.1084 (0.1251)  loss_objectness: 0.0080 (0.0325)  loss_rpn_box_reg: 0.0039 (0.0121)  time: 0.3162  data: 0.0249  max mem: 2688\n",
      "Epoch: [0]  [ 5350/27044]  eta: 1:53:07  lr: 0.001000  loss: 0.2445 (0.3845)  loss_classifier: 0.1017 (0.2151)  loss_box_reg: 0.0977 (0.1250)  loss_objectness: 0.0046 (0.0323)  loss_rpn_box_reg: 0.0053 (0.0121)  time: 0.3111  data: 0.0206  max mem: 2688\n",
      "Epoch: [0]  [ 5400/27044]  eta: 1:52:52  lr: 0.001000  loss: 0.2341 (0.3834)  loss_classifier: 0.1091 (0.2143)  loss_box_reg: 0.1219 (0.1250)  loss_objectness: 0.0035 (0.0321)  loss_rpn_box_reg: 0.0025 (0.0120)  time: 0.3108  data: 0.0206  max mem: 2688\n",
      "Epoch: [0]  [ 5450/27044]  eta: 1:52:36  lr: 0.001000  loss: 0.2080 (0.3819)  loss_classifier: 0.0913 (0.2133)  loss_box_reg: 0.0984 (0.1248)  loss_objectness: 0.0037 (0.0319)  loss_rpn_box_reg: 0.0025 (0.0119)  time: 0.3139  data: 0.0229  max mem: 2688\n",
      "Epoch: [0]  [ 5500/27044]  eta: 1:52:21  lr: 0.001000  loss: 0.2162 (0.3809)  loss_classifier: 0.1089 (0.2126)  loss_box_reg: 0.1085 (0.1248)  loss_objectness: 0.0062 (0.0317)  loss_rpn_box_reg: 0.0048 (0.0119)  time: 0.3137  data: 0.0227  max mem: 2688\n",
      "Epoch: [0]  [ 5550/27044]  eta: 1:52:06  lr: 0.001000  loss: 0.1830 (0.3795)  loss_classifier: 0.0743 (0.2115)  loss_box_reg: 0.0997 (0.1247)  loss_objectness: 0.0031 (0.0314)  loss_rpn_box_reg: 0.0027 (0.0119)  time: 0.3185  data: 0.0248  max mem: 2688\n",
      "Epoch: [0]  [ 5600/27044]  eta: 1:51:51  lr: 0.001000  loss: 0.2711 (0.3786)  loss_classifier: 0.1138 (0.2108)  loss_box_reg: 0.1508 (0.1248)  loss_objectness: 0.0095 (0.0312)  loss_rpn_box_reg: 0.0043 (0.0118)  time: 0.3177  data: 0.0247  max mem: 2688\n",
      "Epoch: [0]  [ 5650/27044]  eta: 1:51:37  lr: 0.001000  loss: 0.2306 (0.3778)  loss_classifier: 0.1042 (0.2101)  loss_box_reg: 0.1135 (0.1248)  loss_objectness: 0.0064 (0.0310)  loss_rpn_box_reg: 0.0033 (0.0118)  time: 0.3173  data: 0.0255  max mem: 2688\n",
      "Epoch: [0]  [ 5700/27044]  eta: 1:51:22  lr: 0.001000  loss: 0.1874 (0.3768)  loss_classifier: 0.0776 (0.2094)  loss_box_reg: 0.0895 (0.1248)  loss_objectness: 0.0043 (0.0308)  loss_rpn_box_reg: 0.0023 (0.0118)  time: 0.3188  data: 0.0252  max mem: 2688\n",
      "Epoch: [0]  [ 5750/27044]  eta: 1:51:08  lr: 0.001000  loss: 0.2006 (0.3759)  loss_classifier: 0.1022 (0.2087)  loss_box_reg: 0.0987 (0.1248)  loss_objectness: 0.0046 (0.0307)  loss_rpn_box_reg: 0.0053 (0.0118)  time: 0.3168  data: 0.0243  max mem: 2688\n",
      "Epoch: [0]  [ 5800/27044]  eta: 1:50:53  lr: 0.001000  loss: 0.2391 (0.3749)  loss_classifier: 0.1071 (0.2079)  loss_box_reg: 0.1179 (0.1247)  loss_objectness: 0.0078 (0.0304)  loss_rpn_box_reg: 0.0062 (0.0118)  time: 0.3156  data: 0.0238  max mem: 2688\n",
      "Epoch: [0]  [ 5850/27044]  eta: 1:50:37  lr: 0.001000  loss: 0.2649 (0.3738)  loss_classifier: 0.1002 (0.2071)  loss_box_reg: 0.1186 (0.1247)  loss_objectness: 0.0032 (0.0303)  loss_rpn_box_reg: 0.0034 (0.0117)  time: 0.3113  data: 0.0200  max mem: 2688\n",
      "Epoch: [0]  [ 5900/27044]  eta: 1:50:21  lr: 0.001000  loss: 0.1946 (0.3726)  loss_classifier: 0.0765 (0.2063)  loss_box_reg: 0.0946 (0.1245)  loss_objectness: 0.0038 (0.0301)  loss_rpn_box_reg: 0.0042 (0.0117)  time: 0.3128  data: 0.0217  max mem: 2688\n",
      "Epoch: [0]  [ 5950/27044]  eta: 1:50:07  lr: 0.001000  loss: 0.2861 (0.3716)  loss_classifier: 0.1075 (0.2056)  loss_box_reg: 0.1109 (0.1245)  loss_objectness: 0.0039 (0.0299)  loss_rpn_box_reg: 0.0046 (0.0116)  time: 0.3180  data: 0.0244  max mem: 2688\n",
      "Epoch: [0]  [ 6000/27044]  eta: 1:49:52  lr: 0.001000  loss: 0.2213 (0.3706)  loss_classifier: 0.1018 (0.2048)  loss_box_reg: 0.0938 (0.1244)  loss_objectness: 0.0042 (0.0297)  loss_rpn_box_reg: 0.0085 (0.0116)  time: 0.3170  data: 0.0245  max mem: 2688\n",
      "Epoch: [0]  [ 6050/27044]  eta: 1:49:37  lr: 0.001000  loss: 0.2420 (0.3696)  loss_classifier: 0.1147 (0.2042)  loss_box_reg: 0.1023 (0.1243)  loss_objectness: 0.0054 (0.0295)  loss_rpn_box_reg: 0.0055 (0.0116)  time: 0.3167  data: 0.0243  max mem: 2688\n",
      "Epoch: [0]  [ 6100/27044]  eta: 1:49:22  lr: 0.001000  loss: 0.2359 (0.3685)  loss_classifier: 0.1135 (0.2034)  loss_box_reg: 0.1034 (0.1242)  loss_objectness: 0.0035 (0.0293)  loss_rpn_box_reg: 0.0035 (0.0116)  time: 0.3159  data: 0.0237  max mem: 2688\n",
      "Epoch: [0]  [ 6150/27044]  eta: 1:49:07  lr: 0.001000  loss: 0.1959 (0.3674)  loss_classifier: 0.0749 (0.2026)  loss_box_reg: 0.0945 (0.1240)  loss_objectness: 0.0075 (0.0292)  loss_rpn_box_reg: 0.0064 (0.0116)  time: 0.3169  data: 0.0233  max mem: 2688\n",
      "Epoch: [0]  [ 6200/27044]  eta: 1:48:52  lr: 0.001000  loss: 0.1761 (0.3666)  loss_classifier: 0.0794 (0.2019)  loss_box_reg: 0.1039 (0.1241)  loss_objectness: 0.0023 (0.0290)  loss_rpn_box_reg: 0.0039 (0.0116)  time: 0.3169  data: 0.0243  max mem: 2688\n",
      "Epoch: [0]  [ 6250/27044]  eta: 1:48:37  lr: 0.001000  loss: 0.1929 (0.3654)  loss_classifier: 0.0751 (0.2010)  loss_box_reg: 0.0945 (0.1240)  loss_objectness: 0.0042 (0.0288)  loss_rpn_box_reg: 0.0056 (0.0115)  time: 0.3186  data: 0.0245  max mem: 2688\n",
      "Epoch: [0]  [ 6300/27044]  eta: 1:48:23  lr: 0.001000  loss: 0.1983 (0.3645)  loss_classifier: 0.0927 (0.2004)  loss_box_reg: 0.0997 (0.1239)  loss_objectness: 0.0083 (0.0287)  loss_rpn_box_reg: 0.0042 (0.0115)  time: 0.3182  data: 0.0266  max mem: 2688\n",
      "Epoch: [0]  [ 6350/27044]  eta: 1:48:07  lr: 0.001000  loss: 0.1695 (0.3634)  loss_classifier: 0.0632 (0.1996)  loss_box_reg: 0.0813 (0.1237)  loss_objectness: 0.0129 (0.0287)  loss_rpn_box_reg: 0.0059 (0.0115)  time: 0.3162  data: 0.0244  max mem: 2688\n",
      "Epoch: [0]  [ 6400/27044]  eta: 1:47:52  lr: 0.001000  loss: 0.1489 (0.3624)  loss_classifier: 0.0654 (0.1988)  loss_box_reg: 0.0765 (0.1236)  loss_objectness: 0.0028 (0.0285)  loss_rpn_box_reg: 0.0027 (0.0115)  time: 0.3167  data: 0.0252  max mem: 2688\n",
      "Epoch: [0]  [ 6450/27044]  eta: 1:47:37  lr: 0.001000  loss: 0.2339 (0.3617)  loss_classifier: 0.1138 (0.1983)  loss_box_reg: 0.1024 (0.1236)  loss_objectness: 0.0038 (0.0283)  loss_rpn_box_reg: 0.0038 (0.0115)  time: 0.3231  data: 0.0269  max mem: 2688\n",
      "Epoch: [0]  [ 6500/27044]  eta: 1:47:22  lr: 0.001000  loss: 0.2767 (0.3609)  loss_classifier: 0.1199 (0.1977)  loss_box_reg: 0.1172 (0.1235)  loss_objectness: 0.0081 (0.0282)  loss_rpn_box_reg: 0.0083 (0.0114)  time: 0.3194  data: 0.0249  max mem: 2688\n",
      "Epoch: [0]  [ 6550/27044]  eta: 1:47:08  lr: 0.001000  loss: 0.1753 (0.3600)  loss_classifier: 0.0891 (0.1971)  loss_box_reg: 0.0885 (0.1234)  loss_objectness: 0.0050 (0.0280)  loss_rpn_box_reg: 0.0020 (0.0114)  time: 0.3173  data: 0.0243  max mem: 2688\n",
      "Epoch: [0]  [ 6600/27044]  eta: 1:46:52  lr: 0.001000  loss: 0.2221 (0.3591)  loss_classifier: 0.0851 (0.1964)  loss_box_reg: 0.1041 (0.1234)  loss_objectness: 0.0040 (0.0279)  loss_rpn_box_reg: 0.0054 (0.0114)  time: 0.3148  data: 0.0235  max mem: 2688\n",
      "Epoch: [0]  [ 6650/27044]  eta: 1:46:37  lr: 0.001000  loss: 0.1610 (0.3583)  loss_classifier: 0.0927 (0.1959)  loss_box_reg: 0.0627 (0.1233)  loss_objectness: 0.0040 (0.0277)  loss_rpn_box_reg: 0.0038 (0.0114)  time: 0.3186  data: 0.0250  max mem: 2688\n",
      "Epoch: [0]  [ 6700/27044]  eta: 1:46:21  lr: 0.001000  loss: 0.2180 (0.3574)  loss_classifier: 0.0978 (0.1953)  loss_box_reg: 0.0952 (0.1232)  loss_objectness: 0.0035 (0.0276)  loss_rpn_box_reg: 0.0029 (0.0113)  time: 0.3138  data: 0.0222  max mem: 2688\n",
      "Epoch: [0]  [ 6750/27044]  eta: 1:46:06  lr: 0.001000  loss: 0.2028 (0.3564)  loss_classifier: 0.0828 (0.1946)  loss_box_reg: 0.1028 (0.1232)  loss_objectness: 0.0025 (0.0274)  loss_rpn_box_reg: 0.0054 (0.0113)  time: 0.3142  data: 0.0225  max mem: 2688\n",
      "Epoch: [0]  [ 6800/27044]  eta: 1:45:50  lr: 0.001000  loss: 0.1892 (0.3555)  loss_classifier: 0.0964 (0.1939)  loss_box_reg: 0.0768 (0.1230)  loss_objectness: 0.0053 (0.0273)  loss_rpn_box_reg: 0.0045 (0.0113)  time: 0.3156  data: 0.0231  max mem: 2688\n",
      "Epoch: [0]  [ 6850/27044]  eta: 1:45:35  lr: 0.001000  loss: 0.2444 (0.3548)  loss_classifier: 0.1152 (0.1934)  loss_box_reg: 0.1235 (0.1230)  loss_objectness: 0.0033 (0.0271)  loss_rpn_box_reg: 0.0042 (0.0112)  time: 0.3142  data: 0.0231  max mem: 2688\n",
      "Epoch: [0]  [ 6900/27044]  eta: 1:45:19  lr: 0.001000  loss: 0.1802 (0.3542)  loss_classifier: 0.0821 (0.1929)  loss_box_reg: 0.0819 (0.1230)  loss_objectness: 0.0023 (0.0270)  loss_rpn_box_reg: 0.0045 (0.0112)  time: 0.3192  data: 0.0272  max mem: 2688\n",
      "Epoch: [0]  [ 6950/27044]  eta: 1:45:04  lr: 0.001000  loss: 0.1892 (0.3535)  loss_classifier: 0.0923 (0.1924)  loss_box_reg: 0.0913 (0.1231)  loss_objectness: 0.0040 (0.0269)  loss_rpn_box_reg: 0.0045 (0.0112)  time: 0.3147  data: 0.0233  max mem: 2688\n",
      "Epoch: [0]  [ 7000/27044]  eta: 1:44:48  lr: 0.001000  loss: 0.2427 (0.3529)  loss_classifier: 0.1131 (0.1919)  loss_box_reg: 0.1149 (0.1231)  loss_objectness: 0.0068 (0.0267)  loss_rpn_box_reg: 0.0039 (0.0111)  time: 0.3122  data: 0.0198  max mem: 2688\n",
      "Epoch: [0]  [ 7050/27044]  eta: 1:44:33  lr: 0.001000  loss: 0.2218 (0.3521)  loss_classifier: 0.1211 (0.1914)  loss_box_reg: 0.1021 (0.1230)  loss_objectness: 0.0045 (0.0266)  loss_rpn_box_reg: 0.0033 (0.0111)  time: 0.3143  data: 0.0228  max mem: 2688\n",
      "Epoch: [0]  [ 7100/27044]  eta: 1:44:18  lr: 0.001000  loss: 0.1927 (0.3512)  loss_classifier: 0.0715 (0.1907)  loss_box_reg: 0.0987 (0.1229)  loss_objectness: 0.0038 (0.0265)  loss_rpn_box_reg: 0.0027 (0.0111)  time: 0.3167  data: 0.0246  max mem: 2688\n",
      "Epoch: [0]  [ 7150/27044]  eta: 1:44:02  lr: 0.001000  loss: 0.2235 (0.3506)  loss_classifier: 0.1035 (0.1902)  loss_box_reg: 0.1135 (0.1229)  loss_objectness: 0.0040 (0.0263)  loss_rpn_box_reg: 0.0027 (0.0111)  time: 0.3179  data: 0.0261  max mem: 2688\n",
      "Epoch: [0]  [ 7200/27044]  eta: 1:43:47  lr: 0.001000  loss: 0.1913 (0.3497)  loss_classifier: 0.0848 (0.1896)  loss_box_reg: 0.0961 (0.1228)  loss_objectness: 0.0020 (0.0262)  loss_rpn_box_reg: 0.0034 (0.0110)  time: 0.3149  data: 0.0236  max mem: 2688\n",
      "Epoch: [0]  [ 7250/27044]  eta: 1:43:31  lr: 0.001000  loss: 0.2041 (0.3488)  loss_classifier: 0.0885 (0.1890)  loss_box_reg: 0.0909 (0.1227)  loss_objectness: 0.0039 (0.0261)  loss_rpn_box_reg: 0.0022 (0.0110)  time: 0.3118  data: 0.0207  max mem: 2688\n",
      "Epoch: [0]  [ 7300/27044]  eta: 1:43:16  lr: 0.001000  loss: 0.2242 (0.3479)  loss_classifier: 0.1001 (0.1884)  loss_box_reg: 0.1056 (0.1226)  loss_objectness: 0.0025 (0.0259)  loss_rpn_box_reg: 0.0026 (0.0110)  time: 0.3148  data: 0.0234  max mem: 2688\n",
      "Epoch: [0]  [ 7350/27044]  eta: 1:43:00  lr: 0.001000  loss: 0.1934 (0.3470)  loss_classifier: 0.0674 (0.1879)  loss_box_reg: 0.0914 (0.1224)  loss_objectness: 0.0016 (0.0258)  loss_rpn_box_reg: 0.0035 (0.0110)  time: 0.3134  data: 0.0222  max mem: 2688\n",
      "Epoch: [0]  [ 7400/27044]  eta: 1:42:44  lr: 0.001000  loss: 0.2558 (0.3462)  loss_classifier: 0.1091 (0.1872)  loss_box_reg: 0.1235 (0.1223)  loss_objectness: 0.0031 (0.0257)  loss_rpn_box_reg: 0.0039 (0.0110)  time: 0.3124  data: 0.0218  max mem: 2688\n",
      "Epoch: [0]  [ 7450/27044]  eta: 1:42:29  lr: 0.001000  loss: 0.1748 (0.3454)  loss_classifier: 0.0776 (0.1867)  loss_box_reg: 0.0979 (0.1222)  loss_objectness: 0.0027 (0.0255)  loss_rpn_box_reg: 0.0033 (0.0109)  time: 0.3152  data: 0.0237  max mem: 2688\n",
      "Epoch: [0]  [ 7500/27044]  eta: 1:42:13  lr: 0.001000  loss: 0.1688 (0.3444)  loss_classifier: 0.0549 (0.1861)  loss_box_reg: 0.0747 (0.1221)  loss_objectness: 0.0053 (0.0254)  loss_rpn_box_reg: 0.0043 (0.0109)  time: 0.3130  data: 0.0219  max mem: 2688\n",
      "Epoch: [0]  [ 7550/27044]  eta: 1:41:58  lr: 0.001000  loss: 0.1827 (0.3436)  loss_classifier: 0.0679 (0.1855)  loss_box_reg: 0.0983 (0.1219)  loss_objectness: 0.0076 (0.0253)  loss_rpn_box_reg: 0.0032 (0.0109)  time: 0.3134  data: 0.0220  max mem: 2688\n",
      "Epoch: [0]  [ 7600/27044]  eta: 1:41:42  lr: 0.001000  loss: 0.1621 (0.3428)  loss_classifier: 0.0672 (0.1850)  loss_box_reg: 0.0858 (0.1218)  loss_objectness: 0.0023 (0.0252)  loss_rpn_box_reg: 0.0022 (0.0108)  time: 0.3148  data: 0.0228  max mem: 2688\n",
      "Epoch: [0]  [ 7650/27044]  eta: 1:41:26  lr: 0.001000  loss: 0.1774 (0.3421)  loss_classifier: 0.0748 (0.1844)  loss_box_reg: 0.1022 (0.1218)  loss_objectness: 0.0041 (0.0251)  loss_rpn_box_reg: 0.0048 (0.0108)  time: 0.3153  data: 0.0231  max mem: 2688\n",
      "Epoch: [0]  [ 7700/27044]  eta: 1:41:11  lr: 0.001000  loss: 0.2828 (0.3416)  loss_classifier: 0.1133 (0.1840)  loss_box_reg: 0.1313 (0.1218)  loss_objectness: 0.0040 (0.0250)  loss_rpn_box_reg: 0.0035 (0.0108)  time: 0.3119  data: 0.0208  max mem: 2688\n",
      "Epoch: [0]  [ 7750/27044]  eta: 1:40:55  lr: 0.001000  loss: 0.1852 (0.3408)  loss_classifier: 0.0890 (0.1835)  loss_box_reg: 0.0966 (0.1218)  loss_objectness: 0.0015 (0.0248)  loss_rpn_box_reg: 0.0045 (0.0108)  time: 0.3181  data: 0.0251  max mem: 2688\n",
      "Epoch: [0]  [ 7800/27044]  eta: 1:40:40  lr: 0.001000  loss: 0.2286 (0.3402)  loss_classifier: 0.0843 (0.1830)  loss_box_reg: 0.1142 (0.1217)  loss_objectness: 0.0056 (0.0247)  loss_rpn_box_reg: 0.0054 (0.0107)  time: 0.3167  data: 0.0250  max mem: 2688\n",
      "Epoch: [0]  [ 7850/27044]  eta: 1:40:24  lr: 0.001000  loss: 0.1951 (0.3397)  loss_classifier: 0.1018 (0.1826)  loss_box_reg: 0.0842 (0.1217)  loss_objectness: 0.0046 (0.0247)  loss_rpn_box_reg: 0.0052 (0.0107)  time: 0.3138  data: 0.0221  max mem: 2688\n",
      "Epoch: [0]  [ 7900/27044]  eta: 1:40:09  lr: 0.001000  loss: 0.3024 (0.3394)  loss_classifier: 0.1382 (0.1823)  loss_box_reg: 0.1439 (0.1218)  loss_objectness: 0.0029 (0.0246)  loss_rpn_box_reg: 0.0046 (0.0107)  time: 0.3144  data: 0.0231  max mem: 2688\n",
      "Epoch: [0]  [ 7950/27044]  eta: 1:39:53  lr: 0.001000  loss: 0.1793 (0.3387)  loss_classifier: 0.0743 (0.1818)  loss_box_reg: 0.0784 (0.1217)  loss_objectness: 0.0031 (0.0245)  loss_rpn_box_reg: 0.0023 (0.0107)  time: 0.3146  data: 0.0226  max mem: 2688\n",
      "Epoch: [0]  [ 8000/27044]  eta: 1:39:37  lr: 0.001000  loss: 0.2318 (0.3382)  loss_classifier: 0.1023 (0.1814)  loss_box_reg: 0.1047 (0.1218)  loss_objectness: 0.0050 (0.0243)  loss_rpn_box_reg: 0.0042 (0.0107)  time: 0.3145  data: 0.0229  max mem: 2688\n",
      "Epoch: [0]  [ 8050/27044]  eta: 1:39:22  lr: 0.001000  loss: 0.1857 (0.3375)  loss_classifier: 0.0857 (0.1809)  loss_box_reg: 0.0990 (0.1217)  loss_objectness: 0.0048 (0.0242)  loss_rpn_box_reg: 0.0046 (0.0106)  time: 0.3141  data: 0.0223  max mem: 2688\n",
      "Epoch: [0]  [ 8100/27044]  eta: 1:39:06  lr: 0.001000  loss: 0.2052 (0.3367)  loss_classifier: 0.0695 (0.1804)  loss_box_reg: 0.1071 (0.1216)  loss_objectness: 0.0029 (0.0241)  loss_rpn_box_reg: 0.0034 (0.0106)  time: 0.3147  data: 0.0224  max mem: 2688\n",
      "Epoch: [0]  [ 8150/27044]  eta: 1:38:50  lr: 0.001000  loss: 0.1787 (0.3360)  loss_classifier: 0.0811 (0.1799)  loss_box_reg: 0.0826 (0.1215)  loss_objectness: 0.0038 (0.0240)  loss_rpn_box_reg: 0.0049 (0.0106)  time: 0.3153  data: 0.0241  max mem: 2688\n",
      "Epoch: [0]  [ 8200/27044]  eta: 1:38:35  lr: 0.001000  loss: 0.2437 (0.3354)  loss_classifier: 0.0889 (0.1794)  loss_box_reg: 0.1036 (0.1214)  loss_objectness: 0.0052 (0.0239)  loss_rpn_box_reg: 0.0034 (0.0106)  time: 0.3134  data: 0.0223  max mem: 2688\n",
      "Epoch: [0]  [ 8250/27044]  eta: 1:38:19  lr: 0.001000  loss: 0.2147 (0.3347)  loss_classifier: 0.0918 (0.1790)  loss_box_reg: 0.1270 (0.1214)  loss_objectness: 0.0027 (0.0238)  loss_rpn_box_reg: 0.0034 (0.0106)  time: 0.3133  data: 0.0224  max mem: 2688\n",
      "Epoch: [0]  [ 8300/27044]  eta: 1:38:03  lr: 0.001000  loss: 0.2299 (0.3343)  loss_classifier: 0.0926 (0.1786)  loss_box_reg: 0.0960 (0.1214)  loss_objectness: 0.0038 (0.0237)  loss_rpn_box_reg: 0.0036 (0.0106)  time: 0.3146  data: 0.0228  max mem: 2688\n",
      "Epoch: [0]  [ 8350/27044]  eta: 1:37:48  lr: 0.001000  loss: 0.1698 (0.3337)  loss_classifier: 0.0751 (0.1783)  loss_box_reg: 0.0864 (0.1213)  loss_objectness: 0.0037 (0.0236)  loss_rpn_box_reg: 0.0036 (0.0105)  time: 0.3128  data: 0.0214  max mem: 2688\n",
      "Epoch: [0]  [ 8400/27044]  eta: 1:37:32  lr: 0.001000  loss: 0.2159 (0.3330)  loss_classifier: 0.0926 (0.1778)  loss_box_reg: 0.0962 (0.1212)  loss_objectness: 0.0036 (0.0235)  loss_rpn_box_reg: 0.0034 (0.0105)  time: 0.3139  data: 0.0224  max mem: 2688\n",
      "Epoch: [0]  [ 8450/27044]  eta: 1:37:16  lr: 0.001000  loss: 0.2201 (0.3324)  loss_classifier: 0.0956 (0.1773)  loss_box_reg: 0.1018 (0.1211)  loss_objectness: 0.0034 (0.0234)  loss_rpn_box_reg: 0.0029 (0.0105)  time: 0.3133  data: 0.0224  max mem: 2688\n",
      "Epoch: [0]  [ 8500/27044]  eta: 1:37:00  lr: 0.001000  loss: 0.2047 (0.3318)  loss_classifier: 0.1031 (0.1770)  loss_box_reg: 0.0993 (0.1211)  loss_objectness: 0.0032 (0.0233)  loss_rpn_box_reg: 0.0026 (0.0105)  time: 0.3125  data: 0.0211  max mem: 2688\n",
      "Epoch: [0]  [ 8550/27044]  eta: 1:36:45  lr: 0.001000  loss: 0.2195 (0.3313)  loss_classifier: 0.0786 (0.1766)  loss_box_reg: 0.0890 (0.1211)  loss_objectness: 0.0042 (0.0233)  loss_rpn_box_reg: 0.0050 (0.0104)  time: 0.3137  data: 0.0229  max mem: 2688\n",
      "Epoch: [0]  [ 8600/27044]  eta: 1:36:29  lr: 0.001000  loss: 0.1763 (0.3309)  loss_classifier: 0.0868 (0.1763)  loss_box_reg: 0.0856 (0.1211)  loss_objectness: 0.0040 (0.0232)  loss_rpn_box_reg: 0.0036 (0.0104)  time: 0.3132  data: 0.0221  max mem: 2688\n",
      "Epoch: [0]  [ 8650/27044]  eta: 1:36:13  lr: 0.001000  loss: 0.1750 (0.3302)  loss_classifier: 0.0624 (0.1758)  loss_box_reg: 0.0932 (0.1210)  loss_objectness: 0.0044 (0.0231)  loss_rpn_box_reg: 0.0041 (0.0104)  time: 0.3139  data: 0.0225  max mem: 2688\n",
      "Epoch: [0]  [ 8700/27044]  eta: 1:35:58  lr: 0.001000  loss: 0.1757 (0.3296)  loss_classifier: 0.0712 (0.1754)  loss_box_reg: 0.0872 (0.1209)  loss_objectness: 0.0036 (0.0230)  loss_rpn_box_reg: 0.0032 (0.0104)  time: 0.3167  data: 0.0252  max mem: 2688\n",
      "Epoch: [0]  [ 8750/27044]  eta: 1:35:42  lr: 0.001000  loss: 0.1617 (0.3288)  loss_classifier: 0.0673 (0.1749)  loss_box_reg: 0.0958 (0.1207)  loss_objectness: 0.0016 (0.0228)  loss_rpn_box_reg: 0.0025 (0.0103)  time: 0.3133  data: 0.0224  max mem: 2688\n",
      "Epoch: [0]  [ 8800/27044]  eta: 1:35:27  lr: 0.001000  loss: 0.1617 (0.3282)  loss_classifier: 0.0644 (0.1744)  loss_box_reg: 0.0825 (0.1206)  loss_objectness: 0.0043 (0.0228)  loss_rpn_box_reg: 0.0035 (0.0103)  time: 0.3172  data: 0.0262  max mem: 2688\n",
      "Epoch: [0]  [ 8850/27044]  eta: 1:35:11  lr: 0.001000  loss: 0.1465 (0.3275)  loss_classifier: 0.0514 (0.1739)  loss_box_reg: 0.0851 (0.1205)  loss_objectness: 0.0027 (0.0227)  loss_rpn_box_reg: 0.0029 (0.0103)  time: 0.3142  data: 0.0230  max mem: 2688\n",
      "Epoch: [0]  [ 8900/27044]  eta: 1:34:56  lr: 0.001000  loss: 0.1590 (0.3269)  loss_classifier: 0.0780 (0.1735)  loss_box_reg: 0.0814 (0.1204)  loss_objectness: 0.0055 (0.0226)  loss_rpn_box_reg: 0.0028 (0.0103)  time: 0.3179  data: 0.0255  max mem: 2688\n",
      "Epoch: [0]  [ 8950/27044]  eta: 1:34:40  lr: 0.001000  loss: 0.2090 (0.3264)  loss_classifier: 0.0815 (0.1732)  loss_box_reg: 0.1090 (0.1204)  loss_objectness: 0.0067 (0.0225)  loss_rpn_box_reg: 0.0061 (0.0103)  time: 0.3182  data: 0.0249  max mem: 2688\n",
      "Epoch: [0]  [ 9000/27044]  eta: 1:34:25  lr: 0.001000  loss: 0.2059 (0.3259)  loss_classifier: 0.0801 (0.1728)  loss_box_reg: 0.1049 (0.1204)  loss_objectness: 0.0039 (0.0224)  loss_rpn_box_reg: 0.0036 (0.0102)  time: 0.3161  data: 0.0232  max mem: 2688\n",
      "Epoch: [0]  [ 9050/27044]  eta: 1:34:10  lr: 0.001000  loss: 0.1800 (0.3253)  loss_classifier: 0.0808 (0.1724)  loss_box_reg: 0.0979 (0.1203)  loss_objectness: 0.0034 (0.0223)  loss_rpn_box_reg: 0.0027 (0.0102)  time: 0.3318  data: 0.0287  max mem: 2688\n",
      "Epoch: [0]  [ 9100/27044]  eta: 1:33:55  lr: 0.001000  loss: 0.2409 (0.3246)  loss_classifier: 0.0896 (0.1719)  loss_box_reg: 0.1308 (0.1202)  loss_objectness: 0.0060 (0.0223)  loss_rpn_box_reg: 0.0080 (0.0102)  time: 0.3249  data: 0.0291  max mem: 2688\n",
      "Epoch: [0]  [ 9150/27044]  eta: 1:33:41  lr: 0.001000  loss: 0.2103 (0.3242)  loss_classifier: 0.1142 (0.1716)  loss_box_reg: 0.0963 (0.1202)  loss_objectness: 0.0045 (0.0222)  loss_rpn_box_reg: 0.0044 (0.0102)  time: 0.3357  data: 0.0273  max mem: 2688\n",
      "Epoch: [0]  [ 9200/27044]  eta: 1:33:27  lr: 0.001000  loss: 0.2219 (0.3237)  loss_classifier: 0.0942 (0.1713)  loss_box_reg: 0.1212 (0.1202)  loss_objectness: 0.0029 (0.0221)  loss_rpn_box_reg: 0.0040 (0.0101)  time: 0.3257  data: 0.0274  max mem: 2688\n",
      "Epoch: [0]  [ 9250/27044]  eta: 1:33:12  lr: 0.001000  loss: 0.1672 (0.3233)  loss_classifier: 0.0712 (0.1709)  loss_box_reg: 0.1063 (0.1202)  loss_objectness: 0.0027 (0.0221)  loss_rpn_box_reg: 0.0029 (0.0101)  time: 0.3176  data: 0.0222  max mem: 2688\n",
      "Epoch: [0]  [ 9300/27044]  eta: 1:32:56  lr: 0.001000  loss: 0.1477 (0.3227)  loss_classifier: 0.0572 (0.1705)  loss_box_reg: 0.0742 (0.1201)  loss_objectness: 0.0049 (0.0220)  loss_rpn_box_reg: 0.0018 (0.0101)  time: 0.3164  data: 0.0242  max mem: 2688\n",
      "Epoch: [0]  [ 9350/27044]  eta: 1:32:41  lr: 0.001000  loss: 0.1991 (0.3221)  loss_classifier: 0.0929 (0.1701)  loss_box_reg: 0.1117 (0.1201)  loss_objectness: 0.0023 (0.0219)  loss_rpn_box_reg: 0.0037 (0.0101)  time: 0.3177  data: 0.0227  max mem: 2688\n",
      "Epoch: [0]  [ 9400/27044]  eta: 1:32:26  lr: 0.001000  loss: 0.2396 (0.3217)  loss_classifier: 0.0735 (0.1698)  loss_box_reg: 0.1023 (0.1200)  loss_objectness: 0.0056 (0.0218)  loss_rpn_box_reg: 0.0035 (0.0101)  time: 0.3143  data: 0.0218  max mem: 2688\n",
      "Epoch: [0]  [ 9450/27044]  eta: 1:32:10  lr: 0.001000  loss: 0.2143 (0.3212)  loss_classifier: 0.0832 (0.1694)  loss_box_reg: 0.0855 (0.1199)  loss_objectness: 0.0036 (0.0218)  loss_rpn_box_reg: 0.0052 (0.0101)  time: 0.3158  data: 0.0233  max mem: 2688\n",
      "Epoch: [0]  [ 9500/27044]  eta: 1:31:54  lr: 0.001000  loss: 0.1763 (0.3206)  loss_classifier: 0.0774 (0.1690)  loss_box_reg: 0.0816 (0.1199)  loss_objectness: 0.0015 (0.0217)  loss_rpn_box_reg: 0.0030 (0.0101)  time: 0.3179  data: 0.0251  max mem: 2688\n",
      "Epoch: [0]  [ 9550/27044]  eta: 1:31:39  lr: 0.001000  loss: 0.1480 (0.3199)  loss_classifier: 0.0699 (0.1686)  loss_box_reg: 0.0944 (0.1197)  loss_objectness: 0.0018 (0.0216)  loss_rpn_box_reg: 0.0024 (0.0100)  time: 0.3157  data: 0.0223  max mem: 2688\n",
      "Epoch: [0]  [ 9600/27044]  eta: 1:31:24  lr: 0.001000  loss: 0.1670 (0.3194)  loss_classifier: 0.0594 (0.1682)  loss_box_reg: 0.0688 (0.1196)  loss_objectness: 0.0081 (0.0216)  loss_rpn_box_reg: 0.0038 (0.0100)  time: 0.3192  data: 0.0250  max mem: 2688\n",
      "Epoch: [0]  [ 9650/27044]  eta: 1:31:08  lr: 0.001000  loss: 0.1572 (0.3190)  loss_classifier: 0.0640 (0.1678)  loss_box_reg: 0.0927 (0.1196)  loss_objectness: 0.0025 (0.0215)  loss_rpn_box_reg: 0.0029 (0.0100)  time: 0.3159  data: 0.0226  max mem: 2688\n",
      "Epoch: [0]  [ 9700/27044]  eta: 1:30:53  lr: 0.001000  loss: 0.2510 (0.3186)  loss_classifier: 0.1197 (0.1676)  loss_box_reg: 0.1281 (0.1196)  loss_objectness: 0.0054 (0.0214)  loss_rpn_box_reg: 0.0065 (0.0100)  time: 0.3223  data: 0.0269  max mem: 2688\n",
      "Epoch: [0]  [ 9750/27044]  eta: 1:30:38  lr: 0.001000  loss: 0.1589 (0.3181)  loss_classifier: 0.0824 (0.1672)  loss_box_reg: 0.0810 (0.1195)  loss_objectness: 0.0022 (0.0214)  loss_rpn_box_reg: 0.0027 (0.0100)  time: 0.3145  data: 0.0218  max mem: 2688\n",
      "Epoch: [0]  [ 9800/27044]  eta: 1:30:22  lr: 0.001000  loss: 0.1784 (0.3176)  loss_classifier: 0.0782 (0.1669)  loss_box_reg: 0.0920 (0.1194)  loss_objectness: 0.0044 (0.0213)  loss_rpn_box_reg: 0.0028 (0.0100)  time: 0.3155  data: 0.0226  max mem: 2688\n",
      "Epoch: [0]  [ 9850/27044]  eta: 1:30:06  lr: 0.001000  loss: 0.1339 (0.3170)  loss_classifier: 0.0474 (0.1666)  loss_box_reg: 0.0733 (0.1193)  loss_objectness: 0.0068 (0.0212)  loss_rpn_box_reg: 0.0049 (0.0100)  time: 0.3143  data: 0.0220  max mem: 2688\n",
      "Epoch: [0]  [ 9900/27044]  eta: 1:29:51  lr: 0.001000  loss: 0.1753 (0.3166)  loss_classifier: 0.0675 (0.1662)  loss_box_reg: 0.0845 (0.1193)  loss_objectness: 0.0021 (0.0211)  loss_rpn_box_reg: 0.0047 (0.0099)  time: 0.3169  data: 0.0247  max mem: 2688\n",
      "Epoch: [0]  [ 9950/27044]  eta: 1:29:35  lr: 0.001000  loss: 0.1883 (0.3161)  loss_classifier: 0.0711 (0.1659)  loss_box_reg: 0.0981 (0.1192)  loss_objectness: 0.0028 (0.0211)  loss_rpn_box_reg: 0.0036 (0.0099)  time: 0.3192  data: 0.0262  max mem: 2688\n",
      "Epoch: [0]  [10000/27044]  eta: 1:29:19  lr: 0.001000  loss: 0.1486 (0.3156)  loss_classifier: 0.0626 (0.1656)  loss_box_reg: 0.0693 (0.1191)  loss_objectness: 0.0033 (0.0210)  loss_rpn_box_reg: 0.0047 (0.0099)  time: 0.3167  data: 0.0244  max mem: 2688\n",
      "Epoch: [0]  [10050/27044]  eta: 1:29:04  lr: 0.001000  loss: 0.1519 (0.3152)  loss_classifier: 0.0604 (0.1654)  loss_box_reg: 0.0683 (0.1191)  loss_objectness: 0.0023 (0.0209)  loss_rpn_box_reg: 0.0022 (0.0099)  time: 0.3112  data: 0.0202  max mem: 2688\n",
      "Epoch: [0]  [10100/27044]  eta: 1:28:48  lr: 0.001000  loss: 0.1920 (0.3147)  loss_classifier: 0.0877 (0.1650)  loss_box_reg: 0.0948 (0.1190)  loss_objectness: 0.0038 (0.0208)  loss_rpn_box_reg: 0.0041 (0.0099)  time: 0.3162  data: 0.0238  max mem: 2688\n",
      "Epoch: [0]  [10150/27044]  eta: 1:28:32  lr: 0.001000  loss: 0.2098 (0.3142)  loss_classifier: 0.0732 (0.1647)  loss_box_reg: 0.0781 (0.1189)  loss_objectness: 0.0015 (0.0207)  loss_rpn_box_reg: 0.0025 (0.0099)  time: 0.3140  data: 0.0217  max mem: 2688\n",
      "Epoch: [0]  [10200/27044]  eta: 1:28:17  lr: 0.001000  loss: 0.1763 (0.3137)  loss_classifier: 0.0531 (0.1644)  loss_box_reg: 0.0868 (0.1188)  loss_objectness: 0.0017 (0.0207)  loss_rpn_box_reg: 0.0027 (0.0098)  time: 0.3196  data: 0.0236  max mem: 2688\n",
      "Epoch: [0]  [10250/27044]  eta: 1:28:02  lr: 0.001000  loss: 0.2510 (0.3134)  loss_classifier: 0.1198 (0.1641)  loss_box_reg: 0.1569 (0.1188)  loss_objectness: 0.0037 (0.0206)  loss_rpn_box_reg: 0.0031 (0.0098)  time: 0.3163  data: 0.0233  max mem: 2688\n",
      "Epoch: [0]  [10300/27044]  eta: 1:27:46  lr: 0.001000  loss: 0.2434 (0.3129)  loss_classifier: 0.0957 (0.1638)  loss_box_reg: 0.1225 (0.1188)  loss_objectness: 0.0061 (0.0205)  loss_rpn_box_reg: 0.0035 (0.0098)  time: 0.3188  data: 0.0247  max mem: 2688\n",
      "Epoch: [0]  [10350/27044]  eta: 1:27:30  lr: 0.001000  loss: 0.1897 (0.3125)  loss_classifier: 0.0930 (0.1636)  loss_box_reg: 0.0842 (0.1187)  loss_objectness: 0.0028 (0.0205)  loss_rpn_box_reg: 0.0020 (0.0098)  time: 0.3135  data: 0.0208  max mem: 2688\n",
      "Epoch: [0]  [10400/27044]  eta: 1:27:15  lr: 0.001000  loss: 0.2032 (0.3121)  loss_classifier: 0.1005 (0.1632)  loss_box_reg: 0.0885 (0.1186)  loss_objectness: 0.0045 (0.0204)  loss_rpn_box_reg: 0.0046 (0.0098)  time: 0.3173  data: 0.0242  max mem: 2688\n",
      "Epoch: [0]  [10450/27044]  eta: 1:26:59  lr: 0.001000  loss: 0.2416 (0.3115)  loss_classifier: 0.1076 (0.1629)  loss_box_reg: 0.1006 (0.1185)  loss_objectness: 0.0067 (0.0203)  loss_rpn_box_reg: 0.0041 (0.0098)  time: 0.3176  data: 0.0230  max mem: 2688\n",
      "Epoch: [0]  [10500/27044]  eta: 1:26:44  lr: 0.001000  loss: 0.1546 (0.3111)  loss_classifier: 0.0554 (0.1626)  loss_box_reg: 0.0728 (0.1185)  loss_objectness: 0.0042 (0.0203)  loss_rpn_box_reg: 0.0045 (0.0097)  time: 0.3176  data: 0.0247  max mem: 2688\n",
      "Epoch: [0]  [10550/27044]  eta: 1:26:28  lr: 0.001000  loss: 0.1490 (0.3106)  loss_classifier: 0.0586 (0.1623)  loss_box_reg: 0.0906 (0.1184)  loss_objectness: 0.0025 (0.0202)  loss_rpn_box_reg: 0.0027 (0.0097)  time: 0.3159  data: 0.0227  max mem: 2688\n",
      "Epoch: [0]  [10600/27044]  eta: 1:26:13  lr: 0.001000  loss: 0.1668 (0.3102)  loss_classifier: 0.0646 (0.1620)  loss_box_reg: 0.0912 (0.1184)  loss_objectness: 0.0035 (0.0201)  loss_rpn_box_reg: 0.0028 (0.0097)  time: 0.3178  data: 0.0236  max mem: 2688\n",
      "Epoch: [0]  [10650/27044]  eta: 1:25:57  lr: 0.001000  loss: 0.1294 (0.3096)  loss_classifier: 0.0486 (0.1616)  loss_box_reg: 0.0761 (0.1183)  loss_objectness: 0.0032 (0.0201)  loss_rpn_box_reg: 0.0032 (0.0097)  time: 0.3194  data: 0.0258  max mem: 2688\n",
      "Epoch: [0]  [10700/27044]  eta: 1:25:42  lr: 0.001000  loss: 0.1687 (0.3091)  loss_classifier: 0.0520 (0.1612)  loss_box_reg: 0.0959 (0.1182)  loss_objectness: 0.0018 (0.0200)  loss_rpn_box_reg: 0.0032 (0.0097)  time: 0.3138  data: 0.0214  max mem: 2688\n",
      "Epoch: [0]  [10750/27044]  eta: 1:25:27  lr: 0.001000  loss: 0.1903 (0.3087)  loss_classifier: 0.0917 (0.1610)  loss_box_reg: 0.0985 (0.1181)  loss_objectness: 0.0025 (0.0199)  loss_rpn_box_reg: 0.0037 (0.0097)  time: 0.3355  data: 0.0302  max mem: 2688\n",
      "Epoch: [0]  [10800/27044]  eta: 1:25:11  lr: 0.001000  loss: 0.1860 (0.3081)  loss_classifier: 0.0725 (0.1606)  loss_box_reg: 0.0689 (0.1180)  loss_objectness: 0.0018 (0.0199)  loss_rpn_box_reg: 0.0026 (0.0096)  time: 0.3205  data: 0.0221  max mem: 2688\n",
      "Epoch: [0]  [10850/27044]  eta: 1:24:56  lr: 0.001000  loss: 0.1565 (0.3075)  loss_classifier: 0.0558 (0.1602)  loss_box_reg: 0.0925 (0.1179)  loss_objectness: 0.0038 (0.0198)  loss_rpn_box_reg: 0.0028 (0.0096)  time: 0.3141  data: 0.0215  max mem: 2688\n",
      "Epoch: [0]  [10900/27044]  eta: 1:24:40  lr: 0.001000  loss: 0.1630 (0.3071)  loss_classifier: 0.0564 (0.1598)  loss_box_reg: 0.1000 (0.1178)  loss_objectness: 0.0035 (0.0198)  loss_rpn_box_reg: 0.0036 (0.0096)  time: 0.3133  data: 0.0211  max mem: 2688\n",
      "Epoch: [0]  [10950/27044]  eta: 1:24:25  lr: 0.001000  loss: 0.1261 (0.3064)  loss_classifier: 0.0588 (0.1594)  loss_box_reg: 0.0659 (0.1177)  loss_objectness: 0.0030 (0.0197)  loss_rpn_box_reg: 0.0025 (0.0096)  time: 0.3166  data: 0.0227  max mem: 2688\n",
      "Epoch: [0]  [11000/27044]  eta: 1:24:09  lr: 0.001000  loss: 0.1631 (0.3059)  loss_classifier: 0.0485 (0.1590)  loss_box_reg: 0.0947 (0.1176)  loss_objectness: 0.0044 (0.0197)  loss_rpn_box_reg: 0.0028 (0.0096)  time: 0.3167  data: 0.0243  max mem: 2688\n",
      "Epoch: [0]  [11050/27044]  eta: 1:23:53  lr: 0.001000  loss: 0.2075 (0.3055)  loss_classifier: 0.1128 (0.1588)  loss_box_reg: 0.0895 (0.1175)  loss_objectness: 0.0076 (0.0196)  loss_rpn_box_reg: 0.0037 (0.0096)  time: 0.3138  data: 0.0214  max mem: 2688\n",
      "Epoch: [0]  [11100/27044]  eta: 1:23:38  lr: 0.001000  loss: 0.2305 (0.3052)  loss_classifier: 0.1219 (0.1585)  loss_box_reg: 0.0989 (0.1175)  loss_objectness: 0.0042 (0.0196)  loss_rpn_box_reg: 0.0028 (0.0095)  time: 0.3112  data: 0.0194  max mem: 2688\n",
      "Epoch: [0]  [11150/27044]  eta: 1:23:22  lr: 0.001000  loss: 0.2293 (0.3047)  loss_classifier: 0.1019 (0.1583)  loss_box_reg: 0.0855 (0.1174)  loss_objectness: 0.0025 (0.0195)  loss_rpn_box_reg: 0.0027 (0.0095)  time: 0.3153  data: 0.0224  max mem: 2688\n",
      "Epoch: [0]  [11200/27044]  eta: 1:23:06  lr: 0.001000  loss: 0.1600 (0.3043)  loss_classifier: 0.0683 (0.1579)  loss_box_reg: 0.0871 (0.1173)  loss_objectness: 0.0044 (0.0195)  loss_rpn_box_reg: 0.0029 (0.0095)  time: 0.3144  data: 0.0221  max mem: 2688\n",
      "Epoch: [0]  [11250/27044]  eta: 1:22:50  lr: 0.001000  loss: 0.1420 (0.3039)  loss_classifier: 0.0452 (0.1577)  loss_box_reg: 0.0913 (0.1172)  loss_objectness: 0.0038 (0.0195)  loss_rpn_box_reg: 0.0030 (0.0095)  time: 0.3166  data: 0.0236  max mem: 2688\n",
      "Epoch: [0]  [11300/27044]  eta: 1:22:35  lr: 0.001000  loss: 0.1342 (0.3033)  loss_classifier: 0.0538 (0.1573)  loss_box_reg: 0.0661 (0.1171)  loss_objectness: 0.0021 (0.0194)  loss_rpn_box_reg: 0.0030 (0.0095)  time: 0.3131  data: 0.0212  max mem: 2688\n",
      "Epoch: [0]  [11350/27044]  eta: 1:22:19  lr: 0.001000  loss: 0.1507 (0.3028)  loss_classifier: 0.0709 (0.1569)  loss_box_reg: 0.0780 (0.1171)  loss_objectness: 0.0022 (0.0193)  loss_rpn_box_reg: 0.0029 (0.0095)  time: 0.3136  data: 0.0219  max mem: 2688\n",
      "Epoch: [0]  [11400/27044]  eta: 1:22:03  lr: 0.001000  loss: 0.1557 (0.3022)  loss_classifier: 0.0751 (0.1566)  loss_box_reg: 0.0873 (0.1169)  loss_objectness: 0.0029 (0.0193)  loss_rpn_box_reg: 0.0022 (0.0095)  time: 0.3167  data: 0.0243  max mem: 2688\n",
      "Epoch: [0]  [11450/27044]  eta: 1:21:47  lr: 0.001000  loss: 0.1479 (0.3018)  loss_classifier: 0.0744 (0.1562)  loss_box_reg: 0.0686 (0.1168)  loss_objectness: 0.0020 (0.0192)  loss_rpn_box_reg: 0.0021 (0.0095)  time: 0.3099  data: 0.0187  max mem: 2688\n",
      "Epoch: [0]  [11500/27044]  eta: 1:21:31  lr: 0.001000  loss: 0.1347 (0.3013)  loss_classifier: 0.0445 (0.1559)  loss_box_reg: 0.0621 (0.1167)  loss_objectness: 0.0026 (0.0192)  loss_rpn_box_reg: 0.0040 (0.0095)  time: 0.3110  data: 0.0213  max mem: 2688\n",
      "Epoch: [0]  [11550/27044]  eta: 1:21:15  lr: 0.001000  loss: 0.1940 (0.3009)  loss_classifier: 0.0851 (0.1557)  loss_box_reg: 0.1050 (0.1167)  loss_objectness: 0.0041 (0.0191)  loss_rpn_box_reg: 0.0039 (0.0094)  time: 0.3086  data: 0.0192  max mem: 2688\n",
      "Epoch: [0]  [11600/27044]  eta: 1:20:59  lr: 0.001000  loss: 0.2518 (0.3006)  loss_classifier: 0.1107 (0.1555)  loss_box_reg: 0.1219 (0.1167)  loss_objectness: 0.0025 (0.0191)  loss_rpn_box_reg: 0.0036 (0.0094)  time: 0.3125  data: 0.0216  max mem: 2688\n",
      "Epoch: [0]  [11650/27044]  eta: 1:20:43  lr: 0.001000  loss: 0.1492 (0.3003)  loss_classifier: 0.0687 (0.1553)  loss_box_reg: 0.0863 (0.1167)  loss_objectness: 0.0025 (0.0190)  loss_rpn_box_reg: 0.0053 (0.0094)  time: 0.3121  data: 0.0208  max mem: 2688\n",
      "Epoch: [0]  [11700/27044]  eta: 1:20:28  lr: 0.001000  loss: 0.1563 (0.3001)  loss_classifier: 0.0517 (0.1551)  loss_box_reg: 0.0921 (0.1167)  loss_objectness: 0.0014 (0.0189)  loss_rpn_box_reg: 0.0030 (0.0094)  time: 0.3145  data: 0.0229  max mem: 2688\n",
      "Epoch: [0]  [11750/27044]  eta: 1:20:12  lr: 0.001000  loss: 0.2436 (0.2999)  loss_classifier: 0.1025 (0.1549)  loss_box_reg: 0.1191 (0.1167)  loss_objectness: 0.0024 (0.0189)  loss_rpn_box_reg: 0.0041 (0.0094)  time: 0.3120  data: 0.0215  max mem: 2688\n",
      "Epoch: [0]  [11800/27044]  eta: 1:19:56  lr: 0.001000  loss: 0.1414 (0.2994)  loss_classifier: 0.0481 (0.1546)  loss_box_reg: 0.0809 (0.1166)  loss_objectness: 0.0018 (0.0188)  loss_rpn_box_reg: 0.0022 (0.0094)  time: 0.3136  data: 0.0221  max mem: 2688\n",
      "Epoch: [0]  [11850/27044]  eta: 1:19:40  lr: 0.001000  loss: 0.1382 (0.2990)  loss_classifier: 0.0520 (0.1543)  loss_box_reg: 0.0723 (0.1165)  loss_objectness: 0.0016 (0.0188)  loss_rpn_box_reg: 0.0025 (0.0094)  time: 0.3095  data: 0.0192  max mem: 2688\n",
      "Epoch: [0]  [11900/27044]  eta: 1:19:24  lr: 0.001000  loss: 0.1710 (0.2987)  loss_classifier: 0.0840 (0.1541)  loss_box_reg: 0.0928 (0.1165)  loss_objectness: 0.0013 (0.0187)  loss_rpn_box_reg: 0.0017 (0.0093)  time: 0.3087  data: 0.0185  max mem: 2688\n",
      "Epoch: [0]  [11950/27044]  eta: 1:19:08  lr: 0.001000  loss: 0.1470 (0.2984)  loss_classifier: 0.0544 (0.1539)  loss_box_reg: 0.0818 (0.1164)  loss_objectness: 0.0023 (0.0187)  loss_rpn_box_reg: 0.0032 (0.0093)  time: 0.3074  data: 0.0179  max mem: 2688\n",
      "Epoch: [0]  [12000/27044]  eta: 1:18:52  lr: 0.001000  loss: 0.1517 (0.2980)  loss_classifier: 0.0476 (0.1536)  loss_box_reg: 0.0824 (0.1164)  loss_objectness: 0.0028 (0.0187)  loss_rpn_box_reg: 0.0025 (0.0093)  time: 0.3084  data: 0.0190  max mem: 2688\n",
      "Epoch: [0]  [12050/27044]  eta: 1:18:35  lr: 0.001000  loss: 0.1570 (0.2976)  loss_classifier: 0.0609 (0.1534)  loss_box_reg: 0.0782 (0.1164)  loss_objectness: 0.0027 (0.0186)  loss_rpn_box_reg: 0.0017 (0.0093)  time: 0.3067  data: 0.0182  max mem: 2688\n",
      "Epoch: [0]  [12100/27044]  eta: 1:18:19  lr: 0.001000  loss: 0.1586 (0.2972)  loss_classifier: 0.0629 (0.1531)  loss_box_reg: 0.0879 (0.1163)  loss_objectness: 0.0029 (0.0186)  loss_rpn_box_reg: 0.0049 (0.0093)  time: 0.3100  data: 0.0206  max mem: 2688\n",
      "Epoch: [0]  [12150/27044]  eta: 1:18:03  lr: 0.001000  loss: 0.1660 (0.2969)  loss_classifier: 0.0627 (0.1529)  loss_box_reg: 0.0944 (0.1163)  loss_objectness: 0.0020 (0.0185)  loss_rpn_box_reg: 0.0016 (0.0092)  time: 0.3114  data: 0.0210  max mem: 2688\n",
      "Epoch: [0]  [12200/27044]  eta: 1:17:48  lr: 0.001000  loss: 0.2095 (0.2965)  loss_classifier: 0.0664 (0.1526)  loss_box_reg: 0.0867 (0.1162)  loss_objectness: 0.0026 (0.0185)  loss_rpn_box_reg: 0.0038 (0.0092)  time: 0.3120  data: 0.0201  max mem: 2688\n",
      "Epoch: [0]  [12250/27044]  eta: 1:17:32  lr: 0.001000  loss: 0.1548 (0.2963)  loss_classifier: 0.0542 (0.1524)  loss_box_reg: 0.1078 (0.1162)  loss_objectness: 0.0025 (0.0184)  loss_rpn_box_reg: 0.0035 (0.0092)  time: 0.3113  data: 0.0198  max mem: 2688\n",
      "Epoch: [0]  [12300/27044]  eta: 1:17:16  lr: 0.001000  loss: 0.1689 (0.2958)  loss_classifier: 0.0513 (0.1521)  loss_box_reg: 0.0920 (0.1161)  loss_objectness: 0.0044 (0.0183)  loss_rpn_box_reg: 0.0035 (0.0092)  time: 0.3144  data: 0.0229  max mem: 2688\n",
      "Epoch: [0]  [12350/27044]  eta: 1:17:00  lr: 0.001000  loss: 0.2651 (0.2956)  loss_classifier: 0.0979 (0.1520)  loss_box_reg: 0.1199 (0.1161)  loss_objectness: 0.0036 (0.0183)  loss_rpn_box_reg: 0.0047 (0.0092)  time: 0.3122  data: 0.0212  max mem: 2688\n",
      "Epoch: [0]  [12400/27044]  eta: 1:16:44  lr: 0.001000  loss: 0.1523 (0.2951)  loss_classifier: 0.0550 (0.1516)  loss_box_reg: 0.0799 (0.1160)  loss_objectness: 0.0018 (0.0182)  loss_rpn_box_reg: 0.0021 (0.0092)  time: 0.3117  data: 0.0206  max mem: 2688\n",
      "Epoch: [0]  [12450/27044]  eta: 1:16:29  lr: 0.001000  loss: 0.1943 (0.2948)  loss_classifier: 0.0932 (0.1515)  loss_box_reg: 0.0823 (0.1160)  loss_objectness: 0.0067 (0.0182)  loss_rpn_box_reg: 0.0025 (0.0092)  time: 0.3066  data: 0.0170  max mem: 2688\n",
      "Epoch: [0]  [12500/27044]  eta: 1:16:13  lr: 0.001000  loss: 0.1494 (0.2945)  loss_classifier: 0.0750 (0.1513)  loss_box_reg: 0.0694 (0.1159)  loss_objectness: 0.0036 (0.0182)  loss_rpn_box_reg: 0.0028 (0.0092)  time: 0.3168  data: 0.0186  max mem: 2688\n",
      "Epoch: [0]  [12550/27044]  eta: 1:15:57  lr: 0.001000  loss: 0.1768 (0.2942)  loss_classifier: 0.0716 (0.1510)  loss_box_reg: 0.0879 (0.1159)  loss_objectness: 0.0045 (0.0181)  loss_rpn_box_reg: 0.0045 (0.0091)  time: 0.3089  data: 0.0189  max mem: 2688\n",
      "Epoch: [0]  [12600/27044]  eta: 1:15:41  lr: 0.001000  loss: 0.1777 (0.2939)  loss_classifier: 0.0788 (0.1508)  loss_box_reg: 0.0911 (0.1159)  loss_objectness: 0.0044 (0.0181)  loss_rpn_box_reg: 0.0025 (0.0091)  time: 0.3154  data: 0.0225  max mem: 2688\n",
      "Epoch: [0]  [12650/27044]  eta: 1:15:26  lr: 0.001000  loss: 0.1463 (0.2935)  loss_classifier: 0.0475 (0.1506)  loss_box_reg: 0.0670 (0.1158)  loss_objectness: 0.0022 (0.0180)  loss_rpn_box_reg: 0.0030 (0.0091)  time: 0.3207  data: 0.0228  max mem: 2688\n",
      "Epoch: [0]  [12700/27044]  eta: 1:15:11  lr: 0.001000  loss: 0.1474 (0.2931)  loss_classifier: 0.0482 (0.1503)  loss_box_reg: 0.0699 (0.1157)  loss_objectness: 0.0011 (0.0180)  loss_rpn_box_reg: 0.0027 (0.0091)  time: 0.3310  data: 0.0274  max mem: 2688\n",
      "Epoch: [0]  [12750/27044]  eta: 1:14:56  lr: 0.001000  loss: 0.1668 (0.2927)  loss_classifier: 0.0459 (0.1500)  loss_box_reg: 0.0750 (0.1156)  loss_objectness: 0.0018 (0.0179)  loss_rpn_box_reg: 0.0028 (0.0091)  time: 0.3238  data: 0.0243  max mem: 2688\n",
      "Epoch: [0]  [12800/27044]  eta: 1:14:40  lr: 0.001000  loss: 0.1755 (0.2923)  loss_classifier: 0.0611 (0.1498)  loss_box_reg: 0.0904 (0.1155)  loss_objectness: 0.0025 (0.0179)  loss_rpn_box_reg: 0.0038 (0.0091)  time: 0.3123  data: 0.0212  max mem: 2688\n",
      "Epoch: [0]  [12850/27044]  eta: 1:14:24  lr: 0.001000  loss: 0.1531 (0.2919)  loss_classifier: 0.0532 (0.1495)  loss_box_reg: 0.0767 (0.1155)  loss_objectness: 0.0022 (0.0178)  loss_rpn_box_reg: 0.0022 (0.0091)  time: 0.3103  data: 0.0191  max mem: 2688\n",
      "Epoch: [0]  [12900/27044]  eta: 1:14:08  lr: 0.001000  loss: 0.1333 (0.2915)  loss_classifier: 0.0439 (0.1492)  loss_box_reg: 0.0796 (0.1154)  loss_objectness: 0.0025 (0.0178)  loss_rpn_box_reg: 0.0037 (0.0091)  time: 0.3124  data: 0.0208  max mem: 2688\n",
      "Epoch: [0]  [12950/27044]  eta: 1:13:53  lr: 0.001000  loss: 0.1283 (0.2910)  loss_classifier: 0.0487 (0.1489)  loss_box_reg: 0.0651 (0.1153)  loss_objectness: 0.0016 (0.0177)  loss_rpn_box_reg: 0.0025 (0.0091)  time: 0.3114  data: 0.0201  max mem: 2688\n",
      "Epoch: [0]  [13000/27044]  eta: 1:13:37  lr: 0.001000  loss: 0.1686 (0.2906)  loss_classifier: 0.0609 (0.1486)  loss_box_reg: 0.0906 (0.1152)  loss_objectness: 0.0030 (0.0177)  loss_rpn_box_reg: 0.0045 (0.0090)  time: 0.3148  data: 0.0228  max mem: 2688\n",
      "Epoch: [0]  [13050/27044]  eta: 1:13:21  lr: 0.001000  loss: 0.1218 (0.2901)  loss_classifier: 0.0470 (0.1484)  loss_box_reg: 0.0663 (0.1151)  loss_objectness: 0.0015 (0.0177)  loss_rpn_box_reg: 0.0028 (0.0090)  time: 0.3146  data: 0.0228  max mem: 2688\n",
      "Epoch: [0]  [13100/27044]  eta: 1:13:05  lr: 0.001000  loss: 0.1356 (0.2897)  loss_classifier: 0.0489 (0.1481)  loss_box_reg: 0.0727 (0.1150)  loss_objectness: 0.0014 (0.0176)  loss_rpn_box_reg: 0.0027 (0.0090)  time: 0.3116  data: 0.0210  max mem: 2688\n",
      "Epoch: [0]  [13150/27044]  eta: 1:12:49  lr: 0.001000  loss: 0.1052 (0.2894)  loss_classifier: 0.0472 (0.1479)  loss_box_reg: 0.0697 (0.1150)  loss_objectness: 0.0014 (0.0176)  loss_rpn_box_reg: 0.0022 (0.0090)  time: 0.3137  data: 0.0226  max mem: 2688\n",
      "Epoch: [0]  [13200/27044]  eta: 1:12:33  lr: 0.001000  loss: 0.1365 (0.2890)  loss_classifier: 0.0567 (0.1476)  loss_box_reg: 0.0694 (0.1149)  loss_objectness: 0.0018 (0.0175)  loss_rpn_box_reg: 0.0026 (0.0090)  time: 0.3101  data: 0.0191  max mem: 2688\n",
      "Epoch: [0]  [13250/27044]  eta: 1:12:18  lr: 0.001000  loss: 0.1774 (0.2886)  loss_classifier: 0.0690 (0.1474)  loss_box_reg: 0.0917 (0.1148)  loss_objectness: 0.0015 (0.0175)  loss_rpn_box_reg: 0.0034 (0.0090)  time: 0.3168  data: 0.0242  max mem: 2688\n",
      "Epoch: [0]  [13300/27044]  eta: 1:12:02  lr: 0.001000  loss: 0.1439 (0.2882)  loss_classifier: 0.0534 (0.1471)  loss_box_reg: 0.0706 (0.1147)  loss_objectness: 0.0011 (0.0174)  loss_rpn_box_reg: 0.0014 (0.0089)  time: 0.3101  data: 0.0202  max mem: 2688\n",
      "Epoch: [0]  [13350/27044]  eta: 1:11:46  lr: 0.001000  loss: 0.1488 (0.2878)  loss_classifier: 0.0633 (0.1469)  loss_box_reg: 0.0850 (0.1147)  loss_objectness: 0.0019 (0.0174)  loss_rpn_box_reg: 0.0025 (0.0089)  time: 0.3077  data: 0.0182  max mem: 2688\n",
      "Epoch: [0]  [13400/27044]  eta: 1:11:30  lr: 0.001000  loss: 0.1430 (0.2875)  loss_classifier: 0.0542 (0.1466)  loss_box_reg: 0.0697 (0.1146)  loss_objectness: 0.0043 (0.0173)  loss_rpn_box_reg: 0.0026 (0.0089)  time: 0.3115  data: 0.0214  max mem: 2688\n",
      "Epoch: [0]  [13450/27044]  eta: 1:11:14  lr: 0.001000  loss: 0.1476 (0.2871)  loss_classifier: 0.0623 (0.1464)  loss_box_reg: 0.0772 (0.1145)  loss_objectness: 0.0043 (0.0173)  loss_rpn_box_reg: 0.0033 (0.0089)  time: 0.3130  data: 0.0219  max mem: 2688\n",
      "Epoch: [0]  [13500/27044]  eta: 1:10:59  lr: 0.001000  loss: 0.1541 (0.2867)  loss_classifier: 0.0521 (0.1461)  loss_box_reg: 0.0847 (0.1144)  loss_objectness: 0.0028 (0.0172)  loss_rpn_box_reg: 0.0030 (0.0089)  time: 0.3138  data: 0.0225  max mem: 2688\n",
      "Epoch: [0]  [13550/27044]  eta: 1:10:43  lr: 0.001000  loss: 0.1409 (0.2863)  loss_classifier: 0.0639 (0.1459)  loss_box_reg: 0.0870 (0.1144)  loss_objectness: 0.0045 (0.0172)  loss_rpn_box_reg: 0.0037 (0.0089)  time: 0.3173  data: 0.0252  max mem: 2688\n",
      "Epoch: [0]  [13600/27044]  eta: 1:10:27  lr: 0.001000  loss: 0.1689 (0.2859)  loss_classifier: 0.0629 (0.1456)  loss_box_reg: 0.0813 (0.1143)  loss_objectness: 0.0039 (0.0172)  loss_rpn_box_reg: 0.0022 (0.0089)  time: 0.3108  data: 0.0207  max mem: 2688\n",
      "Epoch: [0]  [13650/27044]  eta: 1:10:11  lr: 0.001000  loss: 0.1341 (0.2856)  loss_classifier: 0.0561 (0.1455)  loss_box_reg: 0.0790 (0.1142)  loss_objectness: 0.0026 (0.0171)  loss_rpn_box_reg: 0.0025 (0.0089)  time: 0.3137  data: 0.0223  max mem: 2688\n",
      "Epoch: [0]  [13700/27044]  eta: 1:09:55  lr: 0.001000  loss: 0.1298 (0.2853)  loss_classifier: 0.0665 (0.1452)  loss_box_reg: 0.0699 (0.1141)  loss_objectness: 0.0021 (0.0171)  loss_rpn_box_reg: 0.0024 (0.0088)  time: 0.3151  data: 0.0237  max mem: 2688\n",
      "Epoch: [0]  [13750/27044]  eta: 1:09:40  lr: 0.001000  loss: 0.1101 (0.2849)  loss_classifier: 0.0394 (0.1450)  loss_box_reg: 0.0637 (0.1140)  loss_objectness: 0.0022 (0.0170)  loss_rpn_box_reg: 0.0035 (0.0088)  time: 0.3142  data: 0.0235  max mem: 2688\n",
      "Epoch: [0]  [13800/27044]  eta: 1:09:24  lr: 0.001000  loss: 0.2016 (0.2845)  loss_classifier: 0.0723 (0.1448)  loss_box_reg: 0.0990 (0.1139)  loss_objectness: 0.0036 (0.0170)  loss_rpn_box_reg: 0.0040 (0.0088)  time: 0.3162  data: 0.0245  max mem: 2688\n",
      "Epoch: [0]  [13850/27044]  eta: 1:09:08  lr: 0.001000  loss: 0.1909 (0.2842)  loss_classifier: 0.0714 (0.1445)  loss_box_reg: 0.1149 (0.1139)  loss_objectness: 0.0046 (0.0169)  loss_rpn_box_reg: 0.0048 (0.0088)  time: 0.3169  data: 0.0251  max mem: 2688\n",
      "Epoch: [0]  [13900/27044]  eta: 1:08:53  lr: 0.001000  loss: 0.1203 (0.2839)  loss_classifier: 0.0477 (0.1443)  loss_box_reg: 0.0578 (0.1138)  loss_objectness: 0.0012 (0.0169)  loss_rpn_box_reg: 0.0018 (0.0088)  time: 0.3130  data: 0.0218  max mem: 2688\n"
     ]
    }
   ],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "import utilss\n",
    "from IPython.display import clear_output\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Constructing the optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "# SGD\n",
    "optimizer = torch.optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=1, T_mult=2)\n",
    "\n",
    "# Training for no. of Epochs\n",
    "num_epochs = 2\n",
    "\n",
    "\n",
    "losses = []\n",
    "loss_box_reg = []\n",
    "loss_rpn_box_reg = []\n",
    "loss_classifier = []\n",
    "loss_objectness = []\n",
    "\n",
    "stat0 = []\n",
    "stat1 = []\n",
    "stat2 = []\n",
    "stat3 = []\n",
    "stat4 = []\n",
    "stat5 = []\n",
    "stat6 = []\n",
    "stat7 = []\n",
    "stat8 = []\n",
    "stat9 = []\n",
    "stat10 = []\n",
    "stat11 = []\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Engine.py's train_one_epoch function takes both images and targets. to(device)\n",
    "    # Metrics (metric_logger) was returned by train_one_epoch() in engine.py to get losses\n",
    "    metrics = train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=50)\n",
    "    losses.append(float(str(metrics.meters['loss']).split(\" \")[0]))\n",
    "    loss_box_reg.append(float(str(metrics.meters['loss_box_reg']).split(\" \")[0]))\n",
    "    loss_rpn_box_reg.append(float(str(metrics.meters['loss_rpn_box_reg']).split(\" \")[0]))\n",
    "    loss_classifier.append(float(str(metrics.meters['loss_classifier']).split(\" \")[0]))\n",
    "    loss_objectness.append(float(str(metrics.meters['loss_objectness']).split(\" \")[0]))\n",
    "    \n",
    "    # Update the learning rate\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # Evaluate on the test dataset\n",
    "    # _ gives coco_evaL obj from coco_eval.py from CocoEvaluator()\n",
    "    _, metric_logger = evaluate(model, data_loader_test, device=device)\n",
    "    #Stat object is from pycocotools' self.stats in summarize()\n",
    "    #https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocotools/cocoeval.py\n",
    "    stat = _.coco_eval['bbox'].stats\n",
    "    \n",
    "    #Append all stats\n",
    "    stat0.append(stat[0])\n",
    "    stat1.append(stat[1])\n",
    "    stat2.append(stat[2])\n",
    "    stat3.append(stat[3])\n",
    "    stat4.append(stat[4])\n",
    "    stat5.append(stat[5])\n",
    "    stat6.append(stat[6])\n",
    "    stat7.append(stat[7])\n",
    "    stat8.append(stat[8])\n",
    "    stat9.append(stat[9])\n",
    "    stat10.append(stat[10])\n",
    "    stat11.append(stat[11])\n",
    "    \n",
    "    \n",
    "    print('')\n",
    "    print('==================================================')\n",
    "    print('')\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plots'></a>\n",
    "\n",
    "### 3) Evaluation\n",
    "\n",
    "#### Plotting the Stats\n",
    "\n",
    "All the metrics from COCO Evaluation are recorded and plotted below.\n",
    "<br>\n",
    "To understand them, refer to [COCO's Detection Evaluation](https://cocodataset.org/#detection-eval). </br>\n",
    "\n",
    "True Positive (TP): When the IoU over predicted bounding box and ground truth is greater than or equal to the threshold.\n",
    "False Positive (FP): When the IoU over predicted bounding box and ground truth is less than threshold.\n",
    "\n",
    "\n",
    "Average Precision ($AP$) is the number of true positives in the resulting bounding boxes.\n",
    "Average Recall ($AR$) is the proportion of true positives out of possible positives.\n",
    "\n",
    "\n",
    "COCO Evaluation mentions that they make no distinction between AP and mAP, AR and mAP. The AP and AR are averaged over multiple IoU values. They have used 10 IoU thresholds of .50:.05:.95 (start from 0.5 to 0.95 with a step size of 0.05) instead of computing over a single IoU of .50. Averaging ensures better localization.\n",
    "\n",
    "The size of objects (area = small, medium, large) is mesasured in number of pixels.\n",
    "\n",
    "\n",
    "\n",
    "The following can be inferred from the stats of the last iteration:\n",
    "1. The AP @ IoU=0.5:0.95 for area = large is 0.800 which means that when the model detects an object with large area, 80% of the time it matches the ground truth objects.\n",
    "\n",
    "2. The AR @IoU=0.5:0.95 for area = large is 0.800 which means that the model detects 80% of objects with large area, correctly.\n",
    "\n",
    "3. For area = medium and small, the model does not do well. This was probably caused by the small size of dataset and the insufficient number of examples for small and medium sized objects.\n",
    "\n",
    "The following can be inferred from the loss plots:\n",
    "\n",
    "1. $Loss Box Reg$ is the measure of how tightly the model predicted the bounding box around the true object. It can be observed that the model works well to fit the bbox tightly to the object.\n",
    "\n",
    "2. $Loss RPN Box Reg$ measures the performance of network for retrieving the region proposals. The plot shows that further training or tweaking the hyperparameters may be required to decrease the loss. This may require more data to improve the results significantly.\n",
    "\n",
    "3. $Loss Classifier$ measures the performance of the object classification for detected bounding boxes. The plot shows that the model performs well in classifying the objects in the detected bounding boxes.\n",
    "\n",
    "4. $Loss Objectness$ measures the performance of network for retrieving bounding boxes which contain an object. We can infer that the model is detecting the object very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "r,c = 9,2\n",
    "fig, ax = plt.subplots(nrows=r, ncols=c)\n",
    "fig.set_figheight(40)\n",
    "fig.set_figwidth(10)\n",
    "fig.subplots_adjust(left=14,right=15, top=6, bottom=5, hspace=1, wspace=1)\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(r, c, 1)\n",
    "ax1.set_title(\"Losses\")\n",
    "ax2 = plt.subplot(r, c, 2)\n",
    "ax2.set_title(\"Loss Box Reg\")\n",
    "ax3 = plt.subplot(r, c, 3)\n",
    "ax3.set_title(\"Loss RPN Box Reg\")\n",
    "ax4 = plt.subplot(r, c, 4)\n",
    "ax4.set_title(\"Loss Classifier\")\n",
    "ax5 = plt.subplot(r, c, 5)\n",
    "ax5.set_title(\"Loss Objectness\")\n",
    "ax6 = plt.subplot(r, c, 6)\n",
    "ax6.set_title(\"(AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100\")\n",
    "ax7 = plt.subplot(r, c, 7)\n",
    "ax7.set_title(\"(AP) @[ IoU=0.50      | area=   all | maxDets=100\")\n",
    "ax8 = plt.subplot(r, c, 8)\n",
    "ax8.set_title(\"(AP) @[ IoU=0.75      | area=   all | maxDets=100\")\n",
    "ax9 = plt.subplot(r, c, 9)\n",
    "ax9.set_title(\"(AP) @[ IoU=0.50:0.95 | area= small | maxDets=100\")\n",
    "ax10 = plt.subplot(r, c, 10)\n",
    "ax10.set_title(\"(AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100\")\n",
    "ax11 = plt.subplot(r, c, 11)\n",
    "ax11.set_title(\"(AP) @[ IoU=0.50:0.95 | area= large | maxDets=100\")\n",
    "ax12 = plt.subplot(r, c, 12)\n",
    "ax12.set_title(\"(AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1\")\n",
    "ax13 = plt.subplot(r, c, 13)\n",
    "ax13.set_title(\"(AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10\")\n",
    "ax14 = plt.subplot(r, c, 14)\n",
    "ax14.set_title(\"(AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100\")\n",
    "ax15 = plt.subplot(r, c, 15)\n",
    "ax15.set_title(\"(AR) @[ IoU=0.50:0.95 | area= small | maxDets=100\")\n",
    "ax16 = plt.subplot(r, c, 16)\n",
    "ax16.set_title(\"(AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100\")\n",
    "ax17 = plt.subplot(r, c, 17)\n",
    "ax17.set_title(\"(AR) @[ IoU=0.50:0.95 | area= large | maxDets=100\")\n",
    "\n",
    "ax1.plot(losses, 'b')\n",
    "ax2.plot(loss_box_reg, 'b')\n",
    "ax3.plot(loss_rpn_box_reg, 'b')\n",
    "ax4.plot(loss_classifier, 'b')\n",
    "ax5.plot(loss_objectness, 'b')\n",
    "ax1.plot(losses, 'b')\n",
    "ax2.plot(loss_box_reg, 'b')\n",
    "ax3.plot(loss_rpn_box_reg, 'b')\n",
    "ax4.plot(loss_classifier, 'b')\n",
    "ax5.plot(loss_objectness, 'b')\n",
    "ax6.plot(stat0, 'b')\n",
    "ax7.plot(stat1, 'b')\n",
    "ax8.plot(stat2, 'b')\n",
    "ax9.plot(stat3, 'b')\n",
    "ax10.plot(stat4, 'b')\n",
    "ax11.plot(stat5, 'b')\n",
    "ax12.plot(stat6, 'b')\n",
    "ax13.plot(stat7, 'b')\n",
    "ax14.plot(stat8, 'b')\n",
    "ax15.plot(stat9, 'b')\n",
    "ax16.plot(stat10, 'b')\n",
    "ax17.plot(stat11, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the model\n",
    "\n",
    "The model is saved as pickle file and as .pth file with state dictionary so that it can be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#Save the model\n",
    "torch.save(model, r'/home/vorkov/Workspace/Python/TrafficSignDetection/experiments/train2ep_lr0.001_mom0.9.pkl')\n",
    "\n",
    "torch.save(model.state_dict(), 'train2ep_lr0.001_mom0.9.pth')\n",
    "torch.save({\n",
    "    'epoch' : epoch,\n",
    "    \"model_state_dict\" : model.state_dict(),\n",
    "    'optimizer_state_dict' : optimizer.state_dict(),\n",
    "}, 'ckpt2ep_lr0.001_mom0.9.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the losses and stats\n",
    "\n",
    "The loss history and statistics obtained from the metric_logger and coco_eval objects so that we can use them for future evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#Storing losses and stats in pickle format\n",
    "import pickle\n",
    "\n",
    "with open('train2ep_lr0.001_mom0.9.pickle', 'wb') as f:\n",
    "    pickle.dump([losses, loss_box_reg, loss_rpn_box_reg, loss_classifier, loss_objectness, stat0, stat1, stat2, stat3,\n",
    " stat4, stat5, stat6, stat7, stat8, stat9, stat10, stat11], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the saved variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#Uncomment to :\n",
    "\n",
    "#Load vars pickle file to calc mAP and other statistics\n",
    "\"\"\"\n",
    "with open('vars400.pickle', 'rb') as f:\n",
    "    losses, loss_box_reg, loss_rpn_box_reg, loss_classifier, loss_objectness, stat0, stat1, stat2, stat3,\n",
    "    stat4, stat5, stat6, stat7, stat8, stat9, stat10, stat11 = pickle.load(f)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drawing the bounding box for a prediction\n",
    "\n",
    "The code below obtains the predictions made by the model in the format of a dictionary of boxes, labels and scores.\n",
    "\n",
    "##### Non maximum suppression:\n",
    "A number of proposals can be made by the model for the same object. We can filter the unwanted boxes by using Non-maximum suppression. Torchvision's library was used to perform NMS.\n",
    "\n",
    "Next, the Image is converted to the a numpy array from tensor format and then to the RGB format.\n",
    "A dictionary of class ID as keys and values as their string name is declared to display on the image.\n",
    "\n",
    "Finally, for every bounding box, a rectangle box and class text is displayed in the predicted image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def showbbox(model, img):\n",
    "    # The img entered is a tensor in the 0-1 range        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        '''\n",
    "        prediction Like:\n",
    "        [{'boxes': tensor([[1221.7869,  523.7036, 1272.7373,  575.1018],\n",
    "        [ 192.8189,  527.5751,  240.7135,  589.8405],\n",
    "        [ 197.3745,  538.7914,  235.9153,  572.1550],\n",
    "        [ 195.1216,  533.9565,  238.6585,  578.0548],\n",
    "        [ 194.0861,  517.0943,  238.0777,  582.4178]], device='cuda:0'), \n",
    "        'labels': tensor([7, 7, 7, 8, 5], device='cuda:0'), \n",
    "        'scores': tensor([0.9792, 0.9036, 0.2619, 0.2407, 0.0575], device='cuda:0')}]\n",
    "        '''\n",
    "        prediction = model([img.to(device)])\n",
    "\n",
    "    print(prediction)\n",
    "    b = prediction[0]['boxes']\n",
    "    #print(b)\n",
    "    s = prediction[0]['scores']\n",
    "    #print(s)\n",
    "    \n",
    "    #Apply Non-maximum suppression:\n",
    "    keep = torchvision.ops.nms(b,s,0.1)\n",
    "    #print(keep)\n",
    "        \n",
    "    img = img.permute(1,2,0)  # C,H,W_H,W,C, for drawing\n",
    "    img = (img * 255).byte().data.cpu()  # * 255, float to 0-255\n",
    "    img = np.array(img)  # tensor → ndarray\n",
    "    #Convert np array img to right format.\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #Class number coressponding to Classes\n",
    "    classes = {\n",
    "  1: \"2_1\",\n",
    "  2: \"1_23\",\n",
    "  3: \"1_17\",\n",
    "  4: \"3_24\",\n",
    "  5: \"8_2_1\",\n",
    "  6: \"5_20\",\n",
    "  7: \"5_19_1\",\n",
    "  8: \"5_16\",\n",
    "  9: \"3_25\",\n",
    "  10: \"6_16\",\n",
    "  11: \"7_15\",\n",
    "  12: \"2_2\",\n",
    "  13: \"2_4\",\n",
    "  14: \"8_13_1\",\n",
    "  15: \"4_2_1\",\n",
    "  16: \"1_20_3\",\n",
    "  17: \"1_25\",\n",
    "  18: \"3_4\",\n",
    "  19: \"8_3_2\",\n",
    "  20: \"3_4_1\",\n",
    "  21: \"4_1_6\",\n",
    "  22: \"4_2_3\",\n",
    "  23: \"4_1_1\",\n",
    "  24: \"1_33\",\n",
    "  25: \"5_15_5\",\n",
    "  26: \"3_27\",\n",
    "  27: \"1_15\",\n",
    "  28: \"4_1_2_1\",\n",
    "  29: \"6_3_1\",\n",
    "  30: \"8_1_1\",\n",
    "  31: \"6_7\",\n",
    "  32: \"5_15_3\",\n",
    "  33: \"7_3\",\n",
    "  34: \"1_19\",\n",
    "  35: \"6_4\",\n",
    "  36: \"8_1_4\",\n",
    "  37: \"8_8\",\n",
    "  38: \"1_16\",\n",
    "  39: \"1_11_1\",\n",
    "  40: \"6_6\",\n",
    "  41: \"5_15_1\",\n",
    "  42: \"7_2\",\n",
    "  43: \"5_15_2\",\n",
    "  44: \"7_12\",\n",
    "  45: \"3_18\",\n",
    "  46: \"5_6\",\n",
    "  47: \"5_5\",\n",
    "  48: \"7_4\",\n",
    "  49: \"4_1_2\",\n",
    "  50: \"8_2_2\",\n",
    "  51: \"7_11\",\n",
    "  52: \"1_22\",\n",
    "  53: \"1_27\",\n",
    "  54: \"2_3_2\",\n",
    "  55: \"5_15_2_2\",\n",
    "  56: \"1_8\",\n",
    "  57: \"3_13\",\n",
    "  58: \"2_3\",\n",
    "  59: \"8_3_3\",\n",
    "  60: \"2_3_3\",\n",
    "  61: \"7_7\",\n",
    "  62: \"1_11\",\n",
    "  63: \"8_13\",\n",
    "  64: \"1_12_2\",\n",
    "  65: \"1_20\",\n",
    "  66: \"1_12\",\n",
    "  67: \"3_32\",\n",
    "  68: \"2_5\",\n",
    "  69: \"3_1\",\n",
    "  70: \"4_8_2\",\n",
    "  71: \"3_20\",\n",
    "  72: \"3_2\",\n",
    "  73: \"2_3_6\",\n",
    "  74: \"5_22\",\n",
    "  75: \"5_18\",\n",
    "  76: \"2_3_5\",\n",
    "  77: \"7_5\",\n",
    "  78: \"8_4_1\",\n",
    "  79: \"3_14\",\n",
    "  80: \"1_2\",\n",
    "  81: \"1_20_2\",\n",
    "  82: \"4_1_4\",\n",
    "  83: \"7_6\",\n",
    "  84: \"8_1_3\",\n",
    "  85: \"8_3_1\",\n",
    "  86: \"4_3\",\n",
    "  87: \"4_1_5\",\n",
    "  88: \"8_2_3\",\n",
    "  89: \"8_2_4\",\n",
    "  90: \"1_31\",\n",
    "  91: \"3_10\",\n",
    "  92: \"4_2_2\",\n",
    "  93: \"7_1\",\n",
    "  94: \"3_28\",\n",
    "  95: \"4_1_3\",\n",
    "  96: \"5_4\",\n",
    "  97: \"5_3\",\n",
    "  98: \"6_8_2\",\n",
    "  99: \"3_31\",\n",
    "  100: \"6_2\",\n",
    "  101: \"1_21\",\n",
    "  102: \"3_21\",\n",
    "  103: \"1_13\",\n",
    "  104: \"1_14\",\n",
    "  105: \"2_3_4\",\n",
    "  106: \"4_8_3\",\n",
    "  107: \"6_15_2\",\n",
    "  108: \"2_6\",\n",
    "  109: \"3_18_2\",\n",
    "  110: \"4_1_2_2\",\n",
    "  111: \"1_7\",\n",
    "  112: \"3_19\",\n",
    "  113: \"1_18\",\n",
    "  114: \"2_7\",\n",
    "  115: \"8_5_4\",\n",
    "  116: \"5_15_7\",\n",
    "  117: \"5_14\",\n",
    "  118: \"5_21\",\n",
    "  119: \"1_1\",\n",
    "  120: \"6_15_1\",\n",
    "  121: \"8_6_4\",\n",
    "  122: \"8_15\",\n",
    "  123: \"4_5\",\n",
    "  124: \"3_11\",\n",
    "  125: \"8_18\",\n",
    "  126: \"8_4_4\",\n",
    "  127: \"3_30\",\n",
    "  128: \"5_7_1\",\n",
    "  129: \"5_7_2\",\n",
    "  130: \"1_5\",\n",
    "  131: \"3_29\",\n",
    "  132: \"6_15_3\",\n",
    "  133: \"5_12\",\n",
    "  134: \"3_16\",\n",
    "  135: \"1_30\",\n",
    "  136: \"5_11\",\n",
    "  137: \"1_6\",\n",
    "  138: \"8_6_2\",\n",
    "  139: \"6_8_3\",\n",
    "  140: \"3_12\",\n",
    "  141: \"3_33\",\n",
    "  142: \"8_4_3\",\n",
    "  143: \"5_8\",\n",
    "  144: \"8_14\",\n",
    "  145: \"8_17\",\n",
    "  146: \"3_6\",\n",
    "  147: \"1_26\",\n",
    "  148: \"8_5_2\",\n",
    "  149: \"6_8_1\",\n",
    "  150: \"5_17\",\n",
    "  151: \"1_10\",\n",
    "  152: \"8_16\",\n",
    "  153: \"7_18\",\n",
    "  154: \"7_14\",\n",
    "  155: \"8_23\"\n",
    "}\n",
    "    \n",
    "    \n",
    "    for k in range(len(keep)):\n",
    "        xmin = round(prediction[0]['boxes'][k][0].item())\n",
    "        ymin = round(prediction[0]['boxes'][k][1].item())\n",
    "        xmax = round(prediction[0]['boxes'][k][2].item())\n",
    "        ymax = round(prediction[0]['boxes'][k][3].item())\n",
    "        \n",
    "        label = prediction[0]['labels'][k].item()\n",
    "        print(\"Label is: {}\\n===\\n(Xmin, Ymin, Xmax, Ymax) = ({}, {}, {}, {}) \\n===\".format(label, xmin, ymin, xmax, ymax))\n",
    "        \n",
    "        #color = list(np.random.random(size=3)*256)\n",
    "        colors = np.random.uniform(0, 255, size=(43, 3))\n",
    "        \n",
    "        if label in classes:\n",
    "            pt1 = (xmin, ymin)\n",
    "            pt2 = (xmax, ymax)\n",
    "            print(\"Class Label: \"+ classes[label])\n",
    "            score = prediction[0]['scores'][k].item()\n",
    "            print(\"Score: \"+ str(score))\n",
    "            print(\"\\n===============\\n\")\n",
    "            color = list(colors[label])\n",
    "            cv2.rectangle(img, pt1, pt2, color, thickness=2)\n",
    "            cv2.putText(img, classes[label]+\"-\"+str(round(score,2)), (xmin, ymin), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color,\n",
    "                        thickness=2)\n",
    "\n",
    "    plt.figure(figsize=(40,35))\n",
    "    plt.imshow(img)\n",
    "\n",
    "print(\"Function Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Model from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#Load saved model\n",
    "model1 = torch.load(r'/home/vorkov/Workspace/Python/TrafficSignDetection/experiments/train1000.pkl')\n",
    "device = torch.device('cuda')\n",
    "model1.to(device)\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#Test the model:\n",
    "img, _ = dataset_test[99]\n",
    "showbbox(model, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying the original image\n",
    "\n",
    "To check the difference between processed image and original image.\n",
    "\n",
    "It can be observed that using ImageNet's mean and standard deviation values, normalization was performed by default in Faster RCNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#Show original image:\n",
    "img = img.permute(1,2,0)  # C,H,W_H,W,C, for drawing\n",
    "img = (img * 255).byte().data.cpu()  # * 255, float to 0-255\n",
    "img = np.array(img)  # tensor → ndarray\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual check for German Traffic Sign classes:\n",
    "\n",
    "To check for the correctness of class, the below code was written to verify manually by changing the train subfolders' with class_id outputted by the model. This is done for 2 object that were detected above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#Check manually for a specific class of image\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax1.set_title(\"First class\")\n",
    "\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax2.set_title(\"Second class\")\n",
    "\n",
    "i1 = cv2.cvtColor(cv2.imread('/home/vorkov/Workspace/Python/TrafficSignDetection/experiments/train/17/00001.ppm'), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "i2 = cv2.cvtColor(cv2.imread('/home/vorkov/Workspace/Python/TrafficSignDetection/experiments/train/38/00001.ppm'), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "ax1.imshow(i1)\n",
    "ax2.imshow(i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
